#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
é›²ç«¯è‡ªå‹•æ›´æ–°è…³æœ¬ - å°ˆç‚º GitHub Actions è¨­è¨ˆ
æ¯æ—¥è‡ªå‹•ä¸‹è¼‰å°è‚¡è³‡æ–™ä¸¦ä¸Šå‚³åˆ° Supabase

ä½¿ç”¨æ–¹å¼ï¼š
    python cloud_update.py

ç’°å¢ƒè®Šæ•¸ (GitHub Secrets)ï¼š
    SUPABASE_URL: Supabase å°ˆæ¡ˆ URL
    SUPABASE_KEY: Supabase Service Role Key
"""

import os
import sys
import json
import time
import requests
from datetime import datetime, timedelta
from typing import Dict, List, Optional
import math

# Supabase
try:
    from supabase import create_client, Client
    HAS_SUPABASE = True
except ImportError:
    print("âŒ è«‹å®‰è£ supabase: pip install supabase")
    HAS_SUPABASE = False

# ==============================
# è¨­å®š
# ==============================
SUPABASE_URL = os.environ.get("SUPABASE_URL", "https://gqiyvefcldxslrqpqlri.supabase.co")
SUPABASE_KEY = os.environ.get("SUPABASE_KEY", "")

# è«‹æ±‚æ¨™é ­
HEADERS = {
    "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36"
}

# ==============================
# å·¥å…·å‡½æ•¸
# ==============================
def print_flush(msg: str):
    """å³æ™‚è¼¸å‡º"""
    print(msg, flush=True)

def get_today_date_int() -> int:
    """å–å¾—ä»Šæ—¥æ—¥æœŸ (æ•´æ•¸æ ¼å¼ YYYYMMDD)"""
    return int(datetime.now().strftime("%Y%m%d"))

def safe_float(val, default=0.0) -> float:
    """å®‰å…¨è½‰æ›æµ®é»æ•¸"""
    if val is None or val == "" or val == "--" or val == "N/A":
        return default
    try:
        return float(str(val).replace(",", ""))
    except:
        return default

def safe_int(val, default=0) -> int:
    """å®‰å…¨è½‰æ›æ•´æ•¸"""
    if val is None or val == "" or val == "--" or val == "N/A":
        return default
    try:
        return int(float(str(val).replace(",", "")))
    except:
        return default

# ==============================
# è³‡æ–™ä¸‹è¼‰å‡½æ•¸
# ==============================
def download_twse_stocks() -> List[Dict]:
    """ä¸‹è¼‰ TWSE ä¸Šå¸‚è‚¡ç¥¨æ¸…å–®"""
    print_flush("ğŸ“¥ ä¸‹è¼‰ä¸Šå¸‚è‚¡ç¥¨æ¸…å–®...")
    url = "https://www.twse.com.tw/exchangeReport/STOCK_DAY_ALL?response=json"
    
    try:
        r = requests.get(url, headers=HEADERS, timeout=30)
        data = r.json()
        
        stocks = []
        if data.get("stat") == "OK" and data.get("data"):
            for row in data["data"]:
                code = str(row[0]).strip()
                name = str(row[1]).strip()
                
                # Aè¦å‰‡ï¼šåªä¿ç•™æ™®é€šè‚¡
                if not code.isdigit():
                    continue
                if len(code) != 4:
                    continue
                    
                stocks.append({
                    "code": code,
                    "name": name
                })
        
        print_flush(f"  âœ“ ä¸Šå¸‚è‚¡ç¥¨: {len(stocks)} æª”")
        return stocks
    except Exception as e:
        print_flush(f"  âŒ ä¸‹è¼‰å¤±æ•—: {e}")
        return []

def download_tpex_stocks() -> List[Dict]:
    """ä¸‹è¼‰ TPEX ä¸Šæ«ƒè‚¡ç¥¨æ¸…å–®"""
    print_flush("ğŸ“¥ ä¸‹è¼‰ä¸Šæ«ƒè‚¡ç¥¨æ¸…å–®...")
    # ä½¿ç”¨åŸºæœ¬è³‡æ–™ API
    url = "https://www.tpex.org.tw/openapi/v1/tpex_mainboard_quotes"
    
    try:
        r = requests.get(url, headers=HEADERS, timeout=30)
        data = r.json()
        
        stocks = []
        for item in data:
            code = str(item.get("SecuritiesCompanyCode", "")).strip()
            name = str(item.get("CompanyName", "")).strip()
            
            # Aè¦å‰‡
            if not code.isdigit():
                continue
            if len(code) != 4:
                continue
                
            stocks.append({
                "code": code,
                "name": name
            })
        
        print_flush(f"  âœ“ ä¸Šæ«ƒè‚¡ç¥¨: {len(stocks)} æª”")
        return stocks
    except Exception as e:
        print_flush(f"  âŒ ä¸‹è¼‰å¤±æ•—: {e}")

def download_twse_quotes(date_str: str) -> List[Dict]:
    """ä¸‹è¼‰ TWSE ä»Šæ—¥è¡Œæƒ…"""
    print_flush(f"ğŸ“¥ ä¸‹è¼‰ä¸Šå¸‚è¡Œæƒ… ({date_str})...")
    url = "https://www.twse.com.tw/exchangeReport/MI_INDEX"
    params = {
        "response": "json",
        "date": date_str,
        "type": "ALLBUT0999"
    }
    
    try:
        time.sleep(3)  # é¿å…è«‹æ±‚éå¿«
        r = requests.get(url, params=params, headers=HEADERS, timeout=60)
        data = r.json()
        
        quotes = []
        if data.get("stat") == "OK":
            # æ‰¾åˆ°è‚¡åƒ¹è³‡æ–™è¡¨
            tables = data.get("tables", [])
            for table in tables:
                if "è­‰åˆ¸ä»£è™Ÿ" in str(table.get("fields", [])):
                    for row in table.get("data", []):
                        code = str(row[0]).strip()
                        if not code.isdigit() or len(code) != 4:
                            continue
                        
                        # è§£æè³‡æ–™
                        date_int = int(date_str)
                        volume = safe_int(row[2])
                        open_price = safe_float(row[5])
                        high = safe_float(row[6])
                        low = safe_float(row[7])
                        close = safe_float(row[8])
                        change = safe_float(row[10])
                        
                        if close <= 0:
                            continue
                            
                        quotes.append({
                            "code": code,
                            "date_int": date_int,
                            "open": open_price,
                            "high": high,
                            "low": low,
                            "close": close,
                            "volume": volume
                        })
        
        print_flush(f"  âœ“ ä¸Šå¸‚è¡Œæƒ…: {len(quotes)} ç­†")
        return quotes
    except Exception as e:
        print_flush(f"  âŒ ä¸‹è¼‰å¤±æ•—: {e}")
        return []

def download_tpex_quotes(date_str: str) -> List[Dict]:
    """ä¸‹è¼‰ TPEX ä»Šæ—¥è¡Œæƒ… (ä½¿ç”¨ OpenAPI)"""
    print_flush(f"ğŸ“¥ ä¸‹è¼‰ä¸Šæ«ƒè¡Œæƒ… ({date_str})...")
    url = "https://www.tpex.org.tw/openapi/v1/tpex_mainboard_daily_close_quotes"
    
    try:
        time.sleep(2)
        r = requests.get(url, headers=HEADERS, timeout=60)
        data = r.json()
        
        quotes = []
        date_int = int(date_str)
        # OpenAPI é€šå¸¸å›å‚³æœ€æ–°è³‡æ–™ï¼Œæˆ‘å€‘æª¢æŸ¥æ—¥æœŸæ˜¯å¦åŒ¹é…
        # æ ¼å¼å¯èƒ½æ˜¯ "112/12/29" æˆ– "2025/12/29"
        
        for item in data:
            code = str(item.get("SecuritiesCompanyCode", "")).strip()
            if not code.isdigit() or len(code) != 4:
                continue
            
            # æª¢æŸ¥æ—¥æœŸ (æœ‰äº› OpenAPI æœƒåŒ…å«æ—¥æœŸæ¬„ä½)
            # å¦‚æœæ²’æœ‰æ—¥æœŸæ¬„ä½ï¼Œæˆ‘å€‘å‡è¨­å®ƒæ˜¯æœ€æ–°çš„
            item_date = item.get("Date", "")
            if item_date:
                # è™•ç† 112/12/29 æ ¼å¼
                if "/" in item_date:
                    parts = item_date.split("/")
                    if len(parts[0]) == 3: # æ°‘åœ‹å¹´
                        item_date_int = (int(parts[0]) + 1911) * 10000 + int(parts[1]) * 100 + int(parts[2])
                    else:
                        item_date_int = int(parts[0]) * 10000 + int(parts[1]) * 100 + int(parts[2])
                    
                    if item_date_int != date_int:
                        continue

            close = safe_float(item.get("Close", 0))
            open_price = safe_float(item.get("Open", 0))
            high = safe_float(item.get("High", 0))
            low = safe_float(item.get("Low", 0))
            volume = safe_int(item.get("TradingVolume", 0))
            
            if close <= 0:
                continue
                
            quotes.append({
                "code": code,
                "date_int": date_int,
                "open": open_price,
                "high": high,
                "low": low,
                "close": close,
                "volume": volume
            })
        
        print_flush(f"  âœ“ ä¸Šæ«ƒè¡Œæƒ…: {len(quotes)} ç­†")
        return quotes
    except Exception as e:
        print_flush(f"  âŒ ä¸‹è¼‰å¤±æ•—: {e}")
        return []

def upload_to_supabase(supabase: Client, table: str, data: List[Dict], batch_size: int = 1000):
    """æ‰¹æ¬¡ä¸Šå‚³åˆ° Supabase"""
    if not data:
        print_flush(f"  âš  {table}: ç„¡è³‡æ–™")
        return 0
    
    print_flush(f"ğŸ“¤ ä¸Šå‚³ {table} ({len(data)} ç­†)...")
    
    total_batches = math.ceil(len(data) / batch_size)
    success_count = 0
    
    for i in range(total_batches):
        start = i * batch_size
        end = min((i + 1) * batch_size, len(data))
        batch = data[start:end]
        
        try:
            # ä½¿ç”¨ upsert ä¸¦æŒ‡å®šè¡çªæ™‚å¿½ç•¥ (ignore_duplicates=False æœƒæ›´æ–°)
            # å°æ–¼ stock_dataï¼Œæˆ‘å€‘å¸Œæœ›æ›´æ–°ç¾æœ‰è³‡æ–™
            # å°æ–¼ stock_history å’Œ institutional_investorsï¼Œæˆ‘å€‘ä¹Ÿå¸Œæœ›æ›´æ–°
            if table == "stock_data":
                supabase.table(table).upsert(batch, on_conflict="code,date").execute()
            else:
                supabase.table(table).upsert(batch).execute()
                
            success_count += len(batch)
            
            if (i + 1) % 5 == 0 or (i + 1) == total_batches:
                print_flush(f"  é€²åº¦: {i + 1}/{total_batches} ({success_count}/{len(data)})")
        except Exception as e:
            print_flush(f"  âŒ Batch {i + 1} å¤±æ•—: {e}")
    
    print_flush(f"  âœ“ {table}: {success_count}/{len(data)} ç­†")
    return success_count

def download_institutional(date_str: str) -> List[Dict]:
    """ä¸‹è¼‰ä¸‰å¤§æ³•äººè²·è³£è¶… (ä½¿ç”¨ OpenAPI)"""
    print_flush(f"ğŸ“¥ ä¸‹è¼‰æ³•äººè²·è³£è¶… ({date_str})...")
    date_int = int(date_str)
    # date_fmt = f"{date_str[:4]}-{date_str[4:6]}-{date_str[6:8]}" # Remove date_fmt
    combined_data = []

    # 1. TWSE
    # ä¿®æ­£ï¼šä½¿ç”¨æ­£ç¢ºçš„ OpenAPI URL (T86_ALL)
    twse_url = "https://openapi.twse.com.tw/v1/fund/T86_ALL"
    try:
        print_flush("  ğŸ“¥ ä¸‹è¼‰ä¸Šå¸‚æ³•äººè³‡æ–™...")
        r = requests.get(twse_url, headers=HEADERS, timeout=60)
        # æª¢æŸ¥å›æ‡‰æ˜¯å¦ç‚º JSON
        try:
            data = r.json()
        except json.JSONDecodeError:
            print_flush(f"  âš  TWSE å›æ‡‰é JSON: {r.text[:100]}")
            data = []

        for item in data:
            code = str(item.get("Code", "")).strip()
            if not code.isdigit() or len(code) != 4:
                continue
            
            f_net = safe_int(item.get("ForeignInvestorsBuySellNet", 0))
            t_net = safe_int(item.get("InvestmentTrustBuySellNet", 0))
            d_net = safe_int(item.get("DealerBuySellNet", 0))
            
            combined_data.append({
                "code": code,
                "date_int": date_int,
                # "date": date_fmt, # Remove date field
                "foreign_net": f_net,
                "trust_net": t_net,
                "dealer_net": d_net
            })
    except Exception as e:
        print_flush(f"  âš  TWSE æ³•äººè³‡æ–™ä¸‹è¼‰å¤±æ•—: {e}")

    # 2. TPEX
    tpex_url = "https://www.tpex.org.tw/openapi/v1/tpex_3insti_daily_trading"
    try:
        print_flush("  ğŸ“¥ ä¸‹è¼‰ä¸Šæ«ƒæ³•äººè³‡æ–™...")
        time.sleep(2)
        r = requests.get(tpex_url, headers=HEADERS, timeout=60)
        data = r.json()
        for item in data:
            code = str(item.get("SecuritiesCompanyCode", "")).strip()
            if not code.isdigit() or len(code) != 4:
                continue
            
            f_net = safe_int(item.get("ForeignInvestorsBuySellNet", 0))
            t_net = safe_int(item.get("InvestmentTrustBuySellNet", 0))
            d_net = safe_int(item.get("DealerBuySellNet", 0))
            
            combined_data.append({
                "code": code,
                "date_int": date_int,
                # "date": date_fmt, # Remove date field
                "foreign_net": f_net,
                "trust_net": t_net,
                "dealer_net": d_net
            })
    except Exception as e:
        print_flush(f"  âš  TPEX æ³•äººè³‡æ–™ä¸‹è¼‰å¤±æ•—: {e}")
    
    print_flush(f"  âœ“ æ³•äººè²·è³£è¶…: {len(combined_data)} ç­†")
    return combined_data

# ==============================
# ä¸»ç¨‹å¼
# ==============================
def main():
    """ä¸»ç¨‹å¼"""
    print_flush("=" * 50)
    print_flush("ğŸš€ é›²ç«¯è‡ªå‹•æ›´æ–°é–‹å§‹")
    print_flush(f"â° åŸ·è¡Œæ™‚é–“: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print_flush("=" * 50)
    
    # æª¢æŸ¥ç’°å¢ƒ
    if not HAS_SUPABASE:
        sys.exit(1)
    
    if not SUPABASE_KEY:
        print_flush("âŒ ç¼ºå°‘ SUPABASE_KEY ç’°å¢ƒè®Šæ•¸")
        sys.exit(1)
    
    # åˆå§‹åŒ– Supabase
    try:
        supabase: Client = create_client(SUPABASE_URL, SUPABASE_KEY)
        print_flush("âœ“ Supabase é€£ç·šæˆåŠŸ")
    except Exception as e:
        print_flush(f"âŒ Supabase é€£ç·šå¤±æ•—: {e}")
        sys.exit(1)
    
    # å–å¾—ä»Šæ—¥æ—¥æœŸ
    today = datetime.now()
    # å¦‚æœæ˜¯é€±æœ«ï¼Œä½¿ç”¨ä¸Šé€±äº”
    if today.weekday() == 5:  # é€±å…­
        today = today - timedelta(days=1)
    elif today.weekday() == 6:  # é€±æ—¥
        today = today - timedelta(days=2)
    
    date_str = today.strftime("%Y%m%d")
    print_flush(f"ğŸ“… æ›´æ–°æ—¥æœŸ: {date_str}")
    
    # Step 1: ä¸‹è¼‰è‚¡ç¥¨æ¸…å–®
    print_flush("\n[Step 1] ä¸‹è¼‰è‚¡ç¥¨æ¸…å–®")
    twse_stocks = download_twse_stocks()
    tpex_stocks = download_tpex_stocks()
    all_stocks = twse_stocks + tpex_stocks
    stock_names = {s["code"]: s["name"] for s in all_stocks}
    
    # Step 2: ä¸‹è¼‰ä»Šæ—¥è¡Œæƒ…
    print_flush("\n[Step 2] ä¸‹è¼‰ä»Šæ—¥è¡Œæƒ…")
    twse_quotes = download_twse_quotes(date_str)
    tpex_quotes = download_tpex_quotes(date_str)
    all_quotes = twse_quotes + tpex_quotes
    
    # ä¸Šå‚³åˆ° stock_history
    if all_quotes:
        upload_to_supabase(supabase, "stock_history", all_quotes)
    
    # ä¸Šå‚³åˆ° stock_data (åˆä½µè‚¡ç¥¨åç¨±å’Œè¡Œæƒ…)
    stock_data_records = []
    for q in all_quotes:
        record = {
            "code": q["code"],
            "name": stock_names.get(q["code"], ""),
            "date": f"{date_str[:4]}-{date_str[4:6]}-{date_str[6:8]}",  # YYYY-MM-DD format
            "open": q["open"],
            "high": q["high"],
            "low": q["low"],
            "close": q["close"],
            "volume": q["volume"]
        }
        stock_data_records.append(record)
    
    if stock_data_records:
        upload_to_supabase(supabase, "stock_data", stock_data_records)
    
    # Step 3: ä¸‹è¼‰æ³•äººè²·è³£è¶…
    print_flush("\n[Step 3] ä¸‹è¼‰æ³•äººè²·è³£è¶…")
    institutional = download_institutional(date_str)
    
    if institutional:
        upload_to_supabase(supabase, "institutional_investors", institutional)
    
    # Step 4: æ›´æ–°åŒæ­¥æ™‚é–“
    print_flush("\n[Step 4] æ›´æ–°åŒæ­¥æ™‚é–“")
    try:
        sync_time = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        supabase.table("sync_status").upsert({
            "id": 1,
            "last_update": sync_time,
            "status": "completed"
        }).execute()
        print_flush(f"âœ“ åŒæ­¥æ™‚é–“å·²æ›´æ–°: {sync_time}")
    except Exception as e:
        print_flush(f"âš  æ›´æ–°åŒæ­¥æ™‚é–“å¤±æ•—: {e}")
    
    # å®Œæˆ
    print_flush("\n" + "=" * 50)
    print_flush("âœ… é›²ç«¯è‡ªå‹•æ›´æ–°å®Œæˆ!")
    print_flush(f"ğŸ“Š è‚¡ç¥¨: {len(all_stocks)} æª”")
    print_flush(f"ğŸ“ˆ è¡Œæƒ…: {len(all_quotes)} ç­†")
    print_flush(f"ğŸ›ï¸ æ³•äºº: {len(institutional)} ç­†")
    print_flush("=" * 50)

if __name__ == "__main__":
    main()
