#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å°ç£è‚¡ç¥¨åˆ†æç³»çµ± v40 Enhanced (å‡ç·šå¤šé ­å„ªåŒ–ç‰ˆ)
æ¶æ§‹å¸«:è³‡æ·±è»Ÿé«”æ¶æ§‹å¸«

ä¿®æ­£é …ç›®:
1. [role] è¦å‰‡åš´æ ¼éµå®ˆï¼ˆç¹é«”ä¸­æ–‡ã€Aè¦å‰‡ã€ä¸‰è¡Œé€²åº¦ã€æ–·æª”çºŒè®€ã€è³‡æ–™é¡¯ç¤ºæ–¹å¼ã€ä½¿ç”¨å®˜æ–¹çš„çœŸå¯¦æ•¸æ“šæŠ“åˆ°ä»€éº¼å°±è¼¸å‡ºä»€éº¼ï¼Œä¸è¦æœ‰æŒ‰ä»»æ„éµè¿”å›/ç¹¼çºŒï¼Œä¸€å¾‹ç›´æ¥é€²å…¥é¸å–®æˆ–é¡¯ç¤º)

v40 Enhanced æ–°å¢ä¿®æ­£:
2. âœ… NVI EMA span: 255 â†’ 200 (å°æ‡‰ WMA200)
3. âœ… VSA é™¤ä»¥é›¶è­¦å‘Š: å®‰å…¨è¨ˆç®— close_pos
4. âœ… å‡ç·šå¤šé ­æƒæå„ªåŒ–:
   - åŠ å…¥äº”æ¢å‡ç·šä¸Šæšæ¢ä»¶ (ä»Šæ—¥ > æ˜¨æ—¥)
   - åŠ å…¥ 0-10% ç¯„åœé™åˆ¶
   - ä¾è·é›¢æœ€é«˜å‡ç·šæ’åº (ç”±è¿‘åˆ°é )
   - æ”¹é€²é¡¯ç¤ºæ ¼å¼
"""
import os
import sys
import time
import json
import re
import sqlite3
import logging
import requests
import threading
import warnings
import pandas as pd
import numpy as np
from pathlib import Path
from datetime import datetime, timedelta
from contextlib import contextmanager
from concurrent.futures import ThreadPoolExecutor, as_completed
# import twstock (Removed)

# ==============================
# ç’°å¢ƒé©é…
# ==============================
try:
    import termios
    import tty
    HAS_TERMIOS = True
except ImportError:
    HAS_TERMIOS = False

warnings.filterwarnings("ignore")
try:
    requests.packages.urllib3.disable_warnings()
    # Monkeypatch requests.get to always use verify=False (Fix for twstock SSL error)
    _original_get = requests.get
    def _patched_get(*args, **kwargs):
        kwargs['verify'] = False
        return _original_get(*args, **kwargs)
    requests.get = _patched_get
except Exception:
    pass

if os.name == 'nt':
    try:
        import ctypes
        import msvcrt
        kernel32 = ctypes.windll.kernel32
        kernel32.SetConsoleMode(kernel32.GetStdHandle(-11), 7)
    except Exception:
        pass

# ==============================
# é…ç½®åƒæ•¸
# ==============================
def get_work_directory():
    if os.name == 'nt':
        return Path(__file__).parent.absolute()
    # Android è·¯å¾‘: ä½¿ç”¨ /sdcard/Download/stock_app (èˆ‡ç”¨æˆ¶ç¾æœ‰è³‡æ–™åº«ä½ç½®ä¸€è‡´)
    android_path = Path('/sdcard/Download/stock_app')
    if android_path.exists() or Path('/sdcard').exists():
        android_path.mkdir(parents=True, exist_ok=True)
        return android_path
    # å‚™ç”¨: å˜—è©¦ /storage/emulated/0/Download/stock_app
    alt_path = Path('/storage/emulated/0/Download/stock_app')
    if alt_path.exists() or Path('/storage/emulated/0').exists():
        alt_path.mkdir(parents=True, exist_ok=True)
        return alt_path
    return Path(__file__).parent.absolute()

WORK_DIR = get_work_directory()
# [Architectural Fix] ç’°å¢ƒæ„ŸçŸ¥: æª¢æ¸¬æ˜¯å¦ç‚º Android ç’°å¢ƒ
# Android çš„ /sdcard é€šå¸¸ä¸æ”¯æ´ WAL æ¨¡å¼æ‰€éœ€çš„ mmap
IS_ANDROID = '/sdcard' in str(WORK_DIR) or os.path.exists('/data/data/com.termux')

if not WORK_DIR.exists():
    WORK_DIR.mkdir(parents=True, exist_ok=True)

DB_FILE = WORK_DIR / 'taiwan_stock.db'
STOCK_LIST_PATH = WORK_DIR / 'stock_list.csv'
PROGRESS_FILE = WORK_DIR / 'download_progress.json'
BACKUP_DIR = WORK_DIR / 'backups'
BACKUP_DIR.mkdir(exist_ok=True)
REQUEST_TIMEOUT = 30

# API è¨­å®š
# [Config] FinMind API Token (User Provided)
FINMIND_TOKEN = "eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJkYXRlIjoiMjAyNS0xMi0wMiAyMDo0MzozMyIsInVzZXJfaWQiOiJ5dW5ndGFuZyAiLCJpcCI6IjIyMy4xMzYuNzguMzQifQ.-dsoTH27eOx4akAmKmHfoEso5g5EMZ-UXTcq59l2_Ds"
FINMIND_URL = "https://api.finmindtrade.com/api/v4/data"
TWSE_BWIBBU_URL = "https://openapi.twse.com.tw/v1/exchangeReport/BWIBBU_ALL"
TWSE_STOCK_DAY_ALL_URL = "https://www.twse.com.tw/exchangeReport/STOCK_DAY_ALL?response=json"
TPEX_MAINBOARD_URL = "https://www.tpex.org.tw/openapi/v1/tpex_mainboard_daily_close_quotes"
TWSE_STOCK_DAY_URL = "https://www.twse.com.tw/rwd/zh/afterTrading/STOCK_DAY"
TPEX_DAILY_TRADING_URL = "https://www.tpex.org.tw/web/stock/aftertrading/daily_trading_info/st43_result.php"

# å…¨åŸŸå¿«å–
GLOBAL_INDICATOR_CACHE = {
    "data": None,
    "timestamp": None,
    "cache_duration": 3600
}

COFFEE_COLOR = '\033[38;5;130m'

# é›²ç«¯åŒæ­¥è¨­å®š
SUPABASE_URL = "https://gqiyvefcldxslrqpqlri.supabase.co"
SUPABASE_KEY = "sb_publishable_yXSGYxyxPMaoVu4MbGK5Vw_IuZsl5yu"
ENABLE_CLOUD_SYNC = bool(SUPABASE_URL and SUPABASE_KEY)

def is_normal_stock(code, name):
    """Aè¦å‰‡: æª¢æŸ¥æ˜¯å¦ç‚ºæ™®é€šè‚¡ - åš´æ ¼ç‰ˆæœ¬"""
    if not code or not name:
        return False
    c = str(code).strip()
    
    # åš´æ ¼: åªæ¥å—4ä½æ•¸å­—ä»£ç¢¼
    if len(c) != 4:
        return False
    
    # å¿…é ˆå…¨éƒ¨æ˜¯æ•¸å­—
    if not c.isdigit():
        return False
    
    # Aè¦å‰‡æ ¸å¿ƒ: ç¬¬ä¸€ä½å¿…é ˆæ˜¯ 1-9 (æ’é™¤0é–‹é ­çš„ETFç­‰)
    if c[0] not in ['1', '2', '3', '4', '5', '6', '7', '8', '9']:
        return False
        
    # æ’é™¤ DR (å­˜è¨—æ†‘è­‰)
    if "DR" in name.upper() or c.startswith('91'):
        return False
    
    # æ’é™¤ç‰¹æ®Šä»£ç¢¼
    if c in ['9999', '0000', '1111', '2222', '3333', '4444', '5555', '6666', '7777', '8888']:
        return False
    
    return True

def get_system_status():
    """å–å¾—ç³»çµ±ç‹€æ…‹è³‡è¨Š"""
    status_info = {
        'last_update': 'ç„¡è³‡æ–™',
        'total_stocks': 0,
        'a_rule_stocks': 0,
        'date_range': ('N/A', 'N/A')
    }
    
    try:
        with db_manager.get_connection() as conn:
            # å–å¾—æœ€å¾Œæ›´æ–°æ—¥æœŸ
            res = conn.execute("SELECT MAX(date) FROM stock_data").fetchone()
            if res and res[0]:
                status_info['last_update'] = res[0]
            
            # å–å¾—ç¸½è‚¡ç¥¨æ•¸
            res = conn.execute("SELECT COUNT(DISTINCT code) FROM stock_data").fetchone()
            status_info['total_stocks'] = res[0] if res else 0
            
            # å–å¾—ç¬¦åˆ A è¦å‰‡çš„è‚¡ç¥¨æ•¸ (å„ªåŒ–: æ”¹ç‚ºåªæŸ¥æœ€æ–°æ—¥æœŸçš„è‚¡ç¥¨ï¼Œé¿å…å…¨è¡¨æƒæ)
            latest_date = status_info['last_update']
            if latest_date != 'ç„¡è³‡æ–™':
                res = conn.execute("SELECT code, name FROM stock_data WHERE date=?", (latest_date,)).fetchall()
                status_info['a_rule_stocks'] = sum(1 for row in res if is_normal_stock(row[0], row[1]))
            else:
                status_info['a_rule_stocks'] = 0
            
            # å–å¾—æ—¥æœŸç¯„åœ
            res = conn.execute("SELECT MIN(date), MAX(date) FROM stock_data").fetchone()
            if res:
                min_date = res[0] if res[0] != 'None' else 'N/A'
                max_date = res[1] if res[1] != 'None' else 'N/A'
                status_info['date_range'] = (min_date or 'N/A', max_date or 'N/A')
    
    except Exception as e:
        print_flush(f"âš  å–å¾—ç³»çµ±ç‹€æ…‹å¤±æ•—: {e}")
    
    return status_info

def check_api_status():
    """æª¢æŸ¥ API å¯ç”¨æ€§"""
    status = {
        'finmind': False,
        'twse': False,
        'tpex': False,
        'supabase': False
    }
    
    # æª¢æŸ¥ Supabase
    if ENABLE_CLOUD_SYNC:
        try:
            headers = {
                "apikey": SUPABASE_KEY,
                "Authorization": f"Bearer {SUPABASE_KEY}"
            }
            url = f"{SUPABASE_URL}/rest/v1/stock_list?select=count"
            response = requests.get(url, headers=headers, timeout=3, verify=False)
            if response.status_code == 200:
                status['supabase'] = True
        except Exception:
            pass
    
    # æª¢æŸ¥ FinMind API
    try:
        url = f"{FINMIND_URL}?dataset=TaiwanStockPrice&stock_id=2330&date=2024-01-01&token={FINMIND_TOKEN}"
        response = requests.get(url, timeout=3, verify=False)
        if response.status_code == 200:
            data = response.json()
            if data.get('status') == 200 or 'data' in data:
                status['finmind'] = True
    except Exception:
        pass
    
    # æª¢æŸ¥ TWSE API
    try:
        response = requests.get(TWSE_BWIBBU_URL, timeout=3, verify=False)
        if response.status_code == 200 and response.json():
            status['twse'] = True
    except Exception:
        pass
    
    # æª¢æŸ¥ TPEx API
    try:
        response = requests.get(TPEX_MAINBOARD_URL, timeout=3, verify=False)
        if response.status_code == 200:
            status['tpex'] = True
    except Exception:
        pass
        
    return status

def display_system_status():
    """é¡¯ç¤ºç³»çµ±ç‹€æ…‹è³‡è¨Šæ¿"""
    print_flush("\n" + "=" * 80)
    print_flush("ğŸ“Š ç³»çµ±ç‹€æ…‹")
    print_flush("-" * 80)
    
    # å–å¾—ç³»çµ±è³‡è¨Š
    sys_status = get_system_status()
    
    # é¡¯ç¤ºè³‡æ–™åº«è³‡è¨Š
    print_flush(f"ğŸ“ è³‡æ–™åº«: {DB_FILE}")
    print_flush(f"ğŸ“… æœ€æ–°æ›´æ–°: {sys_status['last_update']}")
    print_flush(f"ğŸ“ˆ è‚¡ç¥¨ç¸½æ•¸: {sys_status['total_stocks']} æª”")
    print_flush(f"ğŸ“† è³‡æ–™ç¯„åœ: {sys_status['date_range'][0]} ~ {sys_status['date_range'][1]}")
    
    # [å„ªåŒ–] è·³é API æª¢æŸ¥ä»¥åŠ å¿«å•Ÿå‹•é€Ÿåº¦
    print_flush("-" * 80)
    print_flush("ğŸš€ ç³»çµ±å·²å°±ç·’ (å·²ç•¥é API é€£ç·šæª¢æŸ¥)")
    print_flush("=" * 80)

# ==============================
# åŸºç¤è¨­æ–½å±¤
# ==============================
class DatabaseManager:
    _instance = None
    def __new__(cls):
        if cls._instance is None:
            cls._instance = super(DatabaseManager, cls).__new__(cls)
        return cls._instance
    
    @contextmanager
    def get_connection(self, timeout=30, max_retries=5):
        """å–å¾—è³‡æ–™åº«é€£ç·šï¼Œè‡ªå‹•è™•ç† database locked é‡è©¦"""
        conn = None
        last_error = None
        
        for attempt in range(max_retries):
            try:
                conn = sqlite3.connect(DB_FILE, timeout=timeout, isolation_level=None)
                # Android ç’°å¢ƒä¸‹ä¸ä½¿ç”¨ WAL æ¨¡å¼ï¼Œé¿å…æ–‡ä»¶é–å®šå•é¡Œ
                if not IS_ANDROID:
                    conn.execute("PRAGMA journal_mode=WAL;")
                else:
                    # Android ä½¿ç”¨ DELETE æ¨¡å¼ï¼Œä¸¦è¨­ç½®è¼ƒé•·çš„ busy_timeout
                    conn.execute("PRAGMA journal_mode=DELETE;")
                    conn.execute("PRAGMA busy_timeout=30000;")  # 30ç§’ç­‰å¾…é–é‡‹æ”¾
                conn.execute("PRAGMA synchronous=NORMAL;")
                yield conn
                return  # æˆåŠŸå‰‡ç›´æ¥è¿”å›
            except sqlite3.OperationalError as e:
                last_error = e
                if "database is locked" in str(e) or "locked" in str(e).lower():
                    if conn:
                        try:
                            conn.close()
                        except:
                            pass
                        conn = None
                    wait_time = (attempt + 1) * 2  # éå¢ç­‰å¾…: 2, 4, 6, 8, 10 ç§’
                    if attempt < max_retries - 1:
                        print_flush(f"âš  è³‡æ–™åº«è¢«é–å®šï¼Œç­‰å¾… {wait_time} ç§’å¾Œé‡è©¦ ({attempt+1}/{max_retries})...")
                        time.sleep(wait_time)
                    continue
                else:
                    raise
            except sqlite3.Error as e:
                print_flush(f"âŒ è³‡æ–™åº«éŒ¯èª¤: {e}")
                raise
            finally:
                if conn:
                    try:
                        conn.close()
                    except:
                        pass
        
        # æ‰€æœ‰é‡è©¦éƒ½å¤±æ•—
        if last_error:
            print_flush(f"âŒ è³‡æ–™åº«éŒ¯èª¤ (é‡è©¦ {max_retries} æ¬¡å¾Œä»å¤±æ•—): {last_error}")
            raise last_error

db_manager = DatabaseManager()

class ProgressTracker:
    """
    å¼·å¥ç‰ˆé€²åº¦è¿½è¹¤å™¨ (Architectural Enhanced)
    1. Windows VT100 æ”¯æ´ (è§£æ±ºäº‚ç¢¼/æ²å‹•å•é¡Œ)
    2. ç·šç¨‹å®‰å…¨ (è§£æ±ºä¸¦ç™¼è¼¸å‡ºè¡çª)
    3. è‡ªå‹•é™æµ (è§£æ±º IO é˜»å¡èˆ‡æ•ˆèƒ½å•é¡Œ)
    """
    _lock = threading.Lock()
    _last_update_time = 0
    _UPDATE_INTERVAL = 0.1  # é™åˆ¶æœ€å¤§åˆ·æ–°ç‡ç‚º 10 FPS
    
    def __init__(self, total_lines=3):
        self.total_lines = total_lines
        self._initialized = False
        self._enable_windows_vt()
        
    def _enable_windows_vt(self):
        """å•Ÿç”¨ Windows è™›æ“¬çµ‚ç«¯è™•ç† (Virtual Terminal Processing)"""
        if os.name == 'nt':
            try:
                import ctypes
                kernel32 = ctypes.windll.kernel32
                hOut = kernel32.GetStdHandle(-11)
                out_mode = ctypes.c_ulong()
                kernel32.GetConsoleMode(hOut, ctypes.byref(out_mode))
                ENABLE_VIRTUAL_TERMINAL_PROCESSING = 0x0004
                kernel32.SetConsoleMode(hOut, out_mode.value | ENABLE_VIRTUAL_TERMINAL_PROCESSING)
            except Exception:
                pass # å¦‚æœå¤±æ•—ï¼Œé€€å›æ¨™æº–æ¨¡å¼ (å¯èƒ½æœƒæœ‰äº‚ç¢¼ï¼Œä½†è‡³å°‘ä¸å´©æ½°)

    def __enter__(self):
        self.reset()
        return self

    def __exit__(self, exc_type, exc_val, exc_tb):
        # ç¢ºä¿æœ€å¾Œä¸€æ¬¡æ›´æ–°è¢«é¡¯ç¤ºï¼Œä¸¦æ›è¡Œ
        sys.stdout.write('\n' * self.total_lines)
        sys.stdout.flush()

    def update_lines(self, *messages, force=False):
        """
        æ›´æ–°å¤šè¡Œé€²åº¦
        :param messages: è¦é¡¯ç¤ºçš„è¨Šæ¯è¡Œ
        :param force: æ˜¯å¦å¼·åˆ¶æ›´æ–° (å¿½ç•¥é™æµ)
        """
        current_time = time.time()
        if not force and (current_time - self._last_update_time < self._UPDATE_INTERVAL):
            return

        with self._lock:
            # æº–å‚™å…§å®¹ï¼Œä¸è¶³è£œç©ºè¡Œ
            lines = list(messages) + [""] * (self.total_lines - len(messages))
            lines = lines[:self.total_lines]
            
            # æ¸¸æ¨™æ§åˆ¶
            if self._initialized:
                # ä¸Šç§» N è¡Œ
                sys.stdout.write(f'\033[{self.total_lines}A')
            
            for line in lines:
                # æ¸…é™¤æ•´è¡Œ (2K) -> ç§»åˆ°è¡Œé¦– (\r) -> è¼¸å‡ºå…§å®¹ -> æ›è¡Œ (\n)
                # æ³¨æ„: æœ€å¾Œä¸€è¡Œä¸æ‡‰è©²æ›è¡Œï¼Œå¦å‰‡æœƒå¤šå‡ºä¸€è¡Œç©ºè¡Œï¼Œä½†ç‚ºäº†ç°¡å–®èµ·è¦‹ï¼Œæˆ‘å€‘é€™è£¡æ§åˆ¶æ¸¸æ¨™
                # æ›´å¥½çš„åšæ³•æ˜¯: å°å‡ºå…§å®¹ï¼Œç„¶å¾Œæ¸¸æ¨™è‡ªå‹•æœƒåˆ°ä¸‹ä¸€è¡Œ
                sys.stdout.write(f'\033[2K\r{line}\n')
            
            sys.stdout.flush()
            self._initialized = True
            self._last_update_time = current_time

    def reset(self):
        self._initialized = False

    def info(self, message, level=1):
        """å…¼å®¹æ€§æ¥å£: é¡¯ç¤ºä¸€èˆ¬è¨Šæ¯"""
        # é€™è£¡ç°¡åŒ–è™•ç†ï¼Œå°‡è¨Šæ¯é¡¯ç¤ºåœ¨æŒ‡å®šè¡Œ
        # level 1 -> ç¬¬ä¸€è¡Œ, level 2 -> ç¬¬äºŒè¡Œ, level 3 -> ç¬¬ä¸‰è¡Œ
        # ä½† update_lines æ˜¯åŒæ™‚æ›´æ–°å¤šè¡Œï¼Œé€™è£¡æˆ‘å€‘éœ€è¦ç¶­è­·ä¸€å€‹å…§éƒ¨ç‹€æ…‹ä¾†ä¿å­˜å„è¡Œå…§å®¹
        self._update_single_line(message, level)

    def warning(self, message, level=1):
        """å…¼å®¹æ€§æ¥å£: é¡¯ç¤ºè­¦å‘Šè¨Šæ¯"""
        self._update_single_line(f"âš  {message}", level)

    def success(self, message, level=1):
        """å…¼å®¹æ€§æ¥å£: é¡¯ç¤ºæˆåŠŸè¨Šæ¯"""
        self._update_single_line(f"âœ“ {message}", level)

    def error(self, message, level=1):
        """å…¼å®¹æ€§æ¥å£: é¡¯ç¤ºéŒ¯èª¤è¨Šæ¯"""
        self._update_single_line(f"âŒ {message}", level)

    _lines_buffer = ["", "", ""]

    def _update_single_line(self, message, level):
        """æ›´æ–°å–®è¡Œå…§å®¹ä¸¦åˆ·æ–°é¡¯ç¤º"""
        idx = max(0, min(level - 1, 2)) # é™åˆ¶åœ¨ 0-2 ä¹‹é–“
        self._lines_buffer[idx] = message
        self.update_lines(*self._lines_buffer)


# ==============================
# é€²åº¦è¿½è¹¤èˆ‡è³‡æ–™å±¤ (å¾ v34 è£œå……)
# ==============================

# é€²åº¦è¿½è¹¤å‡½æ•¸
def load_progress():
    """è¼‰å…¥é€²åº¦è¿½è¹¤ç³»çµ±"""
    try:
        if PROGRESS_FILE.exists():
            with open(PROGRESS_FILE, 'r', encoding='utf-8') as f:
                progress = json.load(f)
                # ç¢ºä¿æ‰€æœ‰å¿…è¦çš„éµå­˜åœ¨
                if "last_code_index" not in progress:
                    progress["last_code_index"] = 0
                if "missing_stocks" not in progress:
                    progress["missing_stocks"] = []
                if "new_stocks" not in progress:
                    progress["new_stocks"] = []
                if "failed_stocks" not in progress:
                    progress["failed_stocks"] = []
                if "in_progress" not in progress:
                    progress["in_progress"] = None
                # æ–°å¢: stock_list é€²åº¦
                if "stock_list_last_idx" not in progress:
                    progress["stock_list_last_idx"] = 0
                if "stock_list_processed" not in progress:
                    progress["stock_list_processed"] = []
                # æ–°å¢: batch_calculate é€²åº¦
                if "calc_last_idx" not in progress:
                    progress["calc_last_idx"] = 0
                return progress
    except Exception as e:
        print_flush(f"âš  ç„¡æ³•è¼‰å…¥é€²åº¦æª”: {e}")
    return {
        "last_code_index": 0,
        "missing_stocks": [],
        "new_stocks": [],
        "failed_stocks": [],
        "in_progress": None,
        "stock_list_last_idx": 0,
        "stock_list_processed": [],
        "calc_last_idx": 0,
        "timestamp": datetime.now().isoformat()
    }

def save_progress(last_idx=None, missing_stocks=None, new_stocks=None, failed_stocks=None, in_progress=None, 
                  stock_list_last_idx=None, stock_list_processed=None, calc_last_idx=None):
    """å„²å­˜é€²åº¦è¿½è¹¤ç³»çµ± - æ“´å±•ç‰ˆæœ¬æ”¯æ´å¤šç¨®é€²åº¦é¡å‹"""
    try:
        # è¼‰å…¥ç¾æœ‰é€²åº¦
        current = load_progress()
        
        # æ›´æ–°é€²åº¦ï¼ˆåªæ›´æ–°æä¾›çš„åƒæ•¸ï¼‰
        progress = {
            "last_code_index": last_idx if last_idx is not None else current.get("last_code_index", 0),
            "missing_stocks": list(set(missing_stocks)) if missing_stocks is not None else current.get("missing_stocks", []),
            "new_stocks": list(set(new_stocks)) if new_stocks is not None else current.get("new_stocks", []),
            "failed_stocks": list(set(failed_stocks)) if failed_stocks is not None else current.get("failed_stocks", []),
            "in_progress": in_progress if in_progress is not None else current.get("in_progress"),
            "stock_list_last_idx": stock_list_last_idx if stock_list_last_idx is not None else current.get("stock_list_last_idx", 0),
            "stock_list_processed": stock_list_processed if stock_list_processed is not None else current.get("stock_list_processed", []),
            "calc_last_idx": calc_last_idx if calc_last_idx is not None else current.get("calc_last_idx", 0),
            "timestamp": datetime.now().isoformat()
        }
        with open(PROGRESS_FILE, 'w', encoding='utf-8') as f:
            json.dump(progress, f, ensure_ascii=False, indent=2)
    except Exception as e:
        print_flush(f"âš  ç„¡æ³•å„²å­˜é€²åº¦æª”: {e}")

def reset_progress():
    try:
        if PROGRESS_FILE.exists():
            PROGRESS_FILE.unlink()
    except Exception as e:
        print_flush(f"âš  ç„¡æ³•é‡ç½®é€²åº¦æª”: {e}")

def ensure_db():
    with sqlite3.connect(DB_FILE, timeout=30) as conn:
        cur = conn.cursor()
        
        # 1. å»ºç«‹åŸºæœ¬è¡¨çµæ§‹
        cur.execute("""
            CREATE TABLE IF NOT EXISTS stock_data (
                code TEXT,
                name TEXT,
                date TEXT,
                open REAL,
                high REAL,
                low REAL,
                close REAL,
                volume INTEGER,
                close_prev REAL,
                vol_prev INTEGER,
                PRIMARY KEY (code, date)
            )
        """)
        
        # 2. æª¢æŸ¥ä¸¦æ·»åŠ ç¼ºå¤±çš„æ¬„ä½
        columns_to_add = [
            # åŸºç¤æŒ‡æ¨™
            ("ma3", "REAL"), ("ma20", "REAL"), ("ma60", "REAL"), ("ma120", "REAL"), ("ma200", "REAL"),
            ("wma3", "REAL"), ("wma20", "REAL"), ("wma60", "REAL"), ("wma120", "REAL"), ("wma200", "REAL"),
            ("mfi14", "REAL"), ("vwap20", "REAL"), ("chg14_pct", "REAL"), 
            ("rsi", "REAL"), ("macd", "REAL"), ("signal", "REAL"),
            ("vp_poc", "REAL"), ("vp_upper", "REAL"), ("vp_lower", "REAL"),
            ("month_k", "REAL"), ("month_d", "REAL"), # æœˆKD
            ("daily_k", "REAL"), ("daily_d", "REAL"), # æ—¥KD
            ("week_k", "REAL"), ("week_d", "REAL"),   # å‘¨KD
            # å‰æ—¥æŒ‡æ¨™ (ç”¨æ–¼è¶¨å‹¢åˆ¤æ–·)
            ("ma3_prev", "REAL"), ("ma20_prev", "REAL"), ("ma60_prev", "REAL"), ("ma120_prev", "REAL"), ("ma200_prev", "REAL"),
            ("wma3_prev", "REAL"), ("wma20_prev", "REAL"), ("wma60_prev", "REAL"), ("wma120_prev", "REAL"), ("wma200_prev", "REAL"),
            ("mfi14_prev", "REAL"), ("vwap20_prev", "REAL"), ("chg14_pct_prev", "REAL"),
            ("month_k_prev", "REAL"), ("month_d_prev", "REAL"), # æœˆKDå‰å€¼
            ("daily_k_prev", "REAL"), ("daily_d_prev", "REAL"), # æ—¥KDå‰å€¼
            ("week_k_prev", "REAL"), ("week_d_prev", "REAL")    # å‘¨KDå‰å€¼
        ]
        
        # ç²å–ç¾æœ‰æ¬„ä½
        cur.execute("PRAGMA table_info(stock_data)")
        existing_columns = {row[1] for row in cur.fetchall()}
        
        for col_name, col_type in columns_to_add:
            if col_name not in existing_columns:
                try:
                    # print_flush(f"æ­£åœ¨æ·»åŠ æ¬„ä½: {col_name}...")
                    cur.execute(f"ALTER TABLE stock_data ADD COLUMN {col_name} {col_type}")
                except Exception as e:
                    print_flush(f"âš  æ·»åŠ æ¬„ä½ {col_name} å¤±æ•—: {e}")
                    
        # 3. å»ºç«‹ç´¢å¼•
        cur.execute("CREATE INDEX IF NOT EXISTS idx_code_date ON stock_data(code, date)")
        cur.execute("CREATE INDEX IF NOT EXISTS idx_date ON stock_data(date)")
        
        conn.commit()

# get_latest_date_for_code
def get_latest_date_for_code(code):
    try:
        with sqlite3.connect(DB_FILE, timeout=30) as conn:
            cur = conn.cursor()
            cur.execute("SELECT MAX(date) FROM stock_data WHERE code=?", (code,))
            result = cur.fetchone()
            return result[0] if result and result[0] else None
    except Exception as e:
        print_flush(f"âš  ç²å–æœ€æ–°æ—¥æœŸå¤±æ•— {code}: {e}")
        return None


def safe_num(x):
    try:
        if x is None: return None
        return float(str(x).replace(',', ''))
    except:
        return None

def safe_int(x):
    try:
        if x is None: return None
        # è™•ç† bytes é¡å‹ï¼ˆSQLite INTEGER å¯èƒ½å›å‚³ bytesï¼‰
        if isinstance(x, bytes):
            return int.from_bytes(x, byteorder='little', signed=True)
        return int(float(str(x).replace(',', '')))
    except:
        return None

def safe_json_parse(text):
    try:
        return json.loads(text)
    except:
        return None

# DataSource æ¶æ§‹
class DataSource:
    """æ•¸æ“šæºæŠ½è±¡æ¥å£"""
    def __init__(self, progress_tracker=None):
        self.progress = progress_tracker or ProgressTracker()
        self.name = "BaseDataSource"
    
    def fetch_history(self, stock_code, start_date=None, end_date=None, retry=3):
        """ç²å–è‚¡ç¥¨æ­·å²æ•¸æ“š"""
        raise NotImplementedError

class FinMindDataSource(DataSource):
    """FinMind API æ•¸æ“šæº"""
    def __init__(self, progress_tracker=None, silent=False):
        super().__init__(progress_tracker)
        self.name = "FinMind"
        self.url = FINMIND_URL
        self.token = FINMIND_TOKEN
        self.silent = silent  # éœé»˜æ¨¡å¼ï¼Œä¸è¼¸å‡ºè©³ç´°é€²åº¦
    
    def fetch_history(self, stock_code, start_date=None, end_date=None, retry=3):
        """å¾FinMindå–å¾—æ­·å²è³‡æ–™ - å„ªåŒ–ç‰ˆæœ¬ï¼Œåªå–250å€‹äº¤æ˜“æ—¥"""
        try:
            # å¦‚æœæ²’æœ‰æŒ‡å®šé–‹å§‹æ—¥æœŸï¼Œè¨ˆç®—250å€‹äº¤æ˜“æ—¥æ‰€éœ€çš„æ™‚é–“ï¼ˆç´„1å¹´ï¼‰
            if start_date is None:
                # 250å€‹äº¤æ˜“æ—¥ç´„ç­‰æ–¼365å¤©
                start_date = (datetime.now() - timedelta(days=365)).strftime("%Y-%m-%d")
            
            if end_date is None:
                end_date = datetime.now().strftime("%Y-%m-%d")
                
            params = {
                "dataset": "TaiwanStockPrice",
                "data_id": stock_code,
                "start_date": start_date,
                "end_date": end_date,
                "token": self.token,
            }
            
            for attempt in range(retry):
                try:
                    if not self.silent:
                        self.progress.info(f"{self.name}: å˜—è©¦ç²å– {stock_code} ({attempt+1}/{retry})", 1)
                    response = requests.get(
                        self.url, 
                        params=params, 
                        timeout=REQUEST_TIMEOUT, 
                        verify=False
                    )
                    if response.status_code == 429:  # é€Ÿç‡é™åˆ¶
                        if not self.silent:
                            self.progress.warning(f"{self.name}: éå¤šè«‹æ±‚ï¼Œç­‰å¾… 2 ç§’", 1)
                        time.sleep(2)
                        continue
                    if response.status_code == 402: # ä»˜è²»é™åˆ¶/æ¬¡æ•¸ä¸Šé™
                        if not self.silent:
                            self.progress.warning(f"{self.name}: è«‹æ±‚æ¬¡æ•¸é”ä¸Šé™ (402)", 1)
                        return None # ç›´æ¥æ”¾æ£„ï¼Œè®“ Manager åˆ‡æ›
                    if response.status_code != 200:
                        logging.error(f"{self.name}: ç‹€æ…‹ç¢¼ {response.status_code} - {response.text}") # Debug
                        if not self.silent:
                            self.progress.warning(f"{self.name}: ç‹€æ…‹ç¢¼ {response.status_code}", 1)
                        if attempt < retry - 1:
                            time.sleep(1)
                        continue
                    try:
                        data = json.loads(response.text)
                    except Exception as e:
                        data = None
                    
                    if data is None or data.get('status') != 200:
                        logging.error(f"{self.name}: API éŸ¿æ‡‰ç„¡æ•ˆ - {response.text[:100]}") # Debug
                        if not self.silent:
                            self.progress.warning(f"{self.name}: API éŸ¿æ‡‰ç„¡æ•ˆ", 1)
                        if attempt < retry - 1:
                            time.sleep(1)
                        continue
                    if not data.get('data') or len(data['data']) == 0:
                        logging.warning(f"{self.name}: {stock_code} ç„¡æ•¸æ“š") # Debug
                        return None
                    rows = []
                    for item in data['data']:
                        try:
                            date = item.get('date')
                            if not date:
                                continue
                            close = safe_num(item.get('close'))
                            if close is not None and close > 0:
                                rows.append({
                                    'date': date,
                                    'open': safe_num(item.get('open')),
                                    'high': safe_num(item.get('max')),
                                    'low': safe_num(item.get('min')),
                                    'close': close,
                                    'volume': safe_int(item.get('Trading_Volume')),
                                    'amount': safe_num(item.get('Trading_money'))
                                })
                        except Exception as e:
                            if not self.silent:
                                self.progress.warning(f"è™•ç†æ•¸æ“šæ™‚å‡ºéŒ¯: {str(e)}", 2)
                            continue
                    
                    if not rows:
                        return None
                    
                    df = pd.DataFrame(rows)
                    
                    # æŒ‰æ—¥æœŸå»é‡: ä¿ç•™ç¬¬ä¸€æ¢ï¼ˆæœ€å®Œæ•´çš„æ•¸æ“šï¼‰
                    df = df.drop_duplicates(subset=['date'], keep='first')
                    
                    # é©—è­‰è³‡æ–™å®Œæ•´æ€§: æª¢æŸ¥æ˜¯å¦æœ‰ NaN æˆ– 0 çš„æ ¸å¿ƒå­—æ®µ
                    df = df[df['close'] > 0]
                    
                    # æŒ‰æ—¥æœŸæ’åº
                    df = df.sort_values('date').reset_index(drop=True)
                    
                    # æŒ‰æ—¥æœŸæ’åº
                    df = df.sort_values('date').reset_index(drop=True)
                    
                    if not self.silent:
                        self.progress.success(f"{self.name}: ç²å– {len(df)} ç­† {stock_code} æ•¸æ“š (å»é‡å¾Œ)", 1)
                    return df
                except Exception as e:
                    logging.error(f"{self.name} éŒ¯èª¤: {str(e)}") # Debug
                    if not self.silent:
                        self.progress.warning(f"{self.name} éŒ¯èª¤: {str(e)}", 1)
                    if attempt < retry - 1:
                        time.sleep(1)
                    continue
            return None
        except Exception as e:
            logging.error(f"{self.name} è‡´å‘½éŒ¯èª¤: {str(e)}") # Debug
            if not self.silent:
                self.progress.error(f"{self.name} è‡´å‘½éŒ¯èª¤: {str(e)}", 1)
            return None

class OfficialAPIDataSource(DataSource):
    """å®˜æ–¹APIæ•¸æ“šæº (TWSE & TPEx)"""
    def __init__(self, progress_tracker=None, silent=False):
        super().__init__(progress_tracker)
        self.name = "OfficialAPI"
        self.silent = silent  # éœé»˜æ¨¡å¼ï¼Œä¸è¼¸å‡ºè©³ç´°é€²åº¦
    
    def fetch_raw_data_twse(self, stock_code, year_month):
        """å¾TWSEç²å–åŸå§‹æ•¸æ“š"""
        date_str = f"{year_month}01"
        params = {
            'response': 'json',
            'date': date_str,
            'stockNo': stock_code
        }
        response = requests.get(
            TWSE_STOCK_DAY_URL, 
            params=params, 
            verify=False, 
            timeout=REQUEST_TIMEOUT
        )
        response.raise_for_status()
        return response.json()
    
    def parse_twse_data(self, response_data):
        """è§£æTWSEå›æ‡‰"""
        if 'data' not in response_data or not response_data['data']:
            return None
        columns = ['æ—¥æœŸ', 'æˆäº¤è‚¡æ•¸', 'æˆäº¤é‡‘é¡', 'æˆäº¤ç­†æ•¸', 'é–‹ç›¤åƒ¹', 'æœ€é«˜åƒ¹', 'æœ€ä½åƒ¹', 'æ”¶ç›¤åƒ¹', 'æ¼²è·Œåƒ¹å·®']
        return pd.DataFrame(response_data['data'], columns=columns)
    
    def fetch_raw_data_tpex(self, stock_code, year_month):
        """å¾TPExç²å–åŸå§‹æ•¸æ“š"""
        if '/' not in year_month:
            year_month = f"{year_month[:4]}/{year_month[4:]}"
        date_str = f"{year_month}/01"
        params = {
            'd': date_str,
            'stk_code': stock_code,
            'o': 'json'
        }
        response = requests.get(
            TPEX_DAILY_TRADING_URL, 
            params=params, 
            verify=False, 
            timeout=REQUEST_TIMEOUT
        )
        response.raise_for_status()
        return response.json()
    
    def parse_tpex_data(self, response_data):
        """è§£æTPExå›æ‡‰"""
        # è™•ç†å…©ç¨®å¯èƒ½çš„å›æ‡‰æ ¼å¼
        if 'aaData' in response_data and response_data['aaData']:
            columns = ['æ—¥æœŸ', 'æˆäº¤è‚¡æ•¸', 'æˆäº¤é‡‘é¡', 'æˆäº¤ç­†æ•¸', 'é–‹ç›¤åƒ¹', 'æœ€é«˜åƒ¹', 'æœ€ä½åƒ¹', 'æ”¶ç›¤åƒ¹', 'æ¼²è·Œåƒ¹å·®']
            df_data = []
            for row in response_data['aaData']:
                if len(row) >= 9:
                    df_data.append(row[:9])
                elif len(row) > 0:
                    padded_row = row + ['0'] * (9 - len(row))
                    df_data.append(padded_row[:9])
            return pd.DataFrame(df_data, columns=columns)
        elif 'reportData' in response_data and 'data' in response_data['reportData']:
            columns = ['æ—¥æœŸ', 'æˆäº¤è‚¡æ•¸', 'æˆäº¤é‡‘é¡', 'æˆäº¤ç­†æ•¸', 'é–‹ç›¤åƒ¹', 'æœ€é«˜åƒ¹', 'æœ€ä½åƒ¹', 'æ”¶ç›¤åƒ¹', 'æ¼²è·Œåƒ¹å·®']
            return pd.DataFrame(response_data['reportData']['data'], columns=columns)
        return None
    
    def fetch_history(self, stock_code, start_date=None, end_date=None, retry=3):
        """å¾å®˜æ–¹APIç²å–æ­·å²è³‡æ–™ (ç¢ºä¿250äº¤æ˜“æ—¥)"""
        try:
            # è¨­ç½®æ™‚é–“ç¯„åœ - ç¢ºä¿ç²å–è¶³å¤ çš„æ­·å²æ•¸æ“š
            if end_date is None:
                end_date = datetime.now()
            else:
                end_date = datetime.strptime(end_date, "%Y-%m-%d")
            # è¨­ç½®é–‹å§‹æ—¥æœŸï¼Œç¢ºä¿è‡³å°‘æœ‰250å€‹äº¤æ˜“æ—¥
            if start_date is None:
                start_date = end_date - timedelta(days=370)
            else:
                start_date = datetime.strptime(start_date, "%Y-%m-%d")
            
            # æº–å‚™æ”¶é›†æ‰€æœ‰æœˆä»½çš„æ•¸æ“š
            all_data = pd.DataFrame()
            current_date = start_date
            month_count = 0
            
            while current_date <= end_date and month_count < 12:  # æœ€å¤šå˜—è©¦12å€‹æœˆ (ç´„250å€‹äº¤æ˜“æ—¥)
                year_month = current_date.strftime("%Y%m")
                if not self.silent:
                    self.progress.info(f"{self.name}: å˜—è©¦ç²å– {stock_code} {year_month}", 1)
                
                # å˜—è©¦TWSE
                try:
                    if not self.silent:
                        self.progress.info("å˜—è©¦TWSE API...", 2)
                    twse_data = self.fetch_raw_data_twse(stock_code, year_month)
                    df = self.parse_twse_data(twse_data)
                    if df is not None and not df.empty:
                        df = convert_numeric_columns(df)
                        df = convert_dates_to_western(df)
                        df = standardize_dataframe(df, "TWSE", stock_code)
                        all_data = pd.concat([all_data, df])
                        if not self.silent:
                            self.progress.success(f"TWSE: ç²å– {len(df)} ç­†æ•¸æ“š", 2)
                        current_date = current_date + timedelta(days=31)
                        month_count += 1
                        continue
                except Exception as e:
                    if not self.silent:
                        self.progress.warning(f"TWSE éŒ¯èª¤: {str(e)}", 2)
                
                # å˜—è©¦TPEx
                try:
                    if not self.silent:
                        self.progress.info("å˜—è©¦TPEx API...", 2)
                    tpex_data = self.fetch_raw_data_tpex(stock_code, year_month)
                    df = self.parse_tpex_data(tpex_data)
                    if df is not None and not df.empty:
                        df = convert_numeric_columns(df)
                        df = convert_dates_to_western(df)
                        df = standardize_dataframe(df, "TPEx", stock_code)
                        all_data = pd.concat([all_data, df])
                        if not self.silent:
                            self.progress.success(f"TPEx: ç²å– {len(df)} ç­†æ•¸æ“š", 2)
                        month_count += 1
                except Exception as e:
                    if not self.silent:
                        self.progress.warning(f"TPEx éŒ¯èª¤: {str(e)}", 2)
                
                # ç§»å‹•åˆ°ä¸‹å€‹æœˆ
                current_date = current_date + timedelta(days=31)
                time.sleep(2.0) # å¢åŠ å»¶é²ä»¥é¿å…è¢«å°é– (F1-005)
            
            # æª¢æŸ¥æ˜¯å¦ç²å–è¶³å¤ æ•¸æ“š
            if not all_data.empty:
                # ç¢ºä¿æ—¥æœŸæ’åº
                all_data = all_data.sort_index()
                # åªä¿ç•™æœ€è¿‘çš„250å€‹äº¤æ˜“æ—¥
                if len(all_data) > 250:
                    all_data = all_data.tail(250)
                
                if not self.silent:
                    self.progress.success(f"{self.name}: ç¸½å…±ç²å– {len(all_data)} ç­† {stock_code} æ•¸æ“š", 1)
                return all_data.reset_index().rename(columns={'æ—¥æœŸ': 'date'})
            return None
        except Exception as e:
            if not self.silent:
                self.progress.error(f"{self.name} è‡´å‘½éŒ¯èª¤: {str(e)}", 1)
            return None

class DataSourceManager:
    """æ•¸æ“šæºç®¡ç†å™¨ - å¯¦ç¾å¤±æ•—è½‰ç§» (ä¿®æ­£: åƒ…ä½¿ç”¨ FinMind)"""
    def __init__(self, progress_tracker=None, silent=False):
        self.progress = progress_tracker or ProgressTracker()
        self.silent = silent
        # ä¿®æ­£: åƒ…ä½¿ç”¨ FinMind (ä½¿ç”¨è€…è¦æ±‚å–æ¶ˆå‚™æ´)
        self.sources = [
            FinMindDataSource(progress_tracker, silent=silent)
        ]
    
    def fetch_history(self, stock_code, start_date=None, end_date=None, retry=3):
        """å˜—è©¦æ‰€æœ‰æ•¸æ“šæºï¼Œç›´åˆ°æˆåŠŸæˆ–å…¨éƒ¨å¤±æ•—"""
        for i, source in enumerate(self.sources):
            if not self.silent:
                self.progress.info(f"å˜—è©¦ä½¿ç”¨ {source.name} ç²å– {stock_code} æ•¸æ“š...", 1)
            df = source.fetch_history(stock_code, start_date, end_date, retry)
            if df is not None and not df.empty:
                return df
            
            if not self.silent:
                self.progress.warning(f"{source.name} ç„¡æ³•ç²å– {stock_code} æ•¸æ“š", 1)
            if i < len(self.sources) - 1:
                self.progress.info(f"æ­£åœ¨åˆ‡æ›è‡³ä¸‹ä¸€å€‹æ•¸æ“šæº: {self.sources[i+1].name}...", 1)
                
        self.progress.error(f"æ‰€æœ‰æ•¸æ“šæºéƒ½ç„¡æ³•ç²å– {stock_code} æ•¸æ“š", 1)
        return None


def setup_logging():
    log_file = WORK_DIR / 'system.log'
    logger = logging.getLogger()
    logger.setLevel(logging.INFO)
    if logger.handlers: return
    file_handler = logging.FileHandler(log_file, encoding='utf-8', mode='a')
    file_handler.setFormatter(logging.Formatter('%(asctime)s - %(levelname)s - %(message)s'))
    logger.addHandler(file_handler)

setup_logging()
def print_flush(s="", end="\n"):
    print(s, end=end)
    sys.stdout.flush()

# ==============================
# å·¥å…·å‡½æ•¸
# ==============================
def safe_num(v):
    if v is None: return 0.0
    if isinstance(v, (int, float)): return float(v)
    try:
        v_str = str(v).replace(',', '').strip()
        if v_str == '' or v_str == '--': return 0.0
        return float(v_str)
    except ValueError: return 0.0

def safe_int(v):
    if v is None: return 0
    if isinstance(v, (int, float)): return int(v)
    try:
        v_str = str(v).replace(',', '').strip()
        if v_str == '' or v_str == '--': return 0
        return int(float(v_str))
    except ValueError: return 0

def safe_float_preserving_none(value, default=None):
    if value is None: return default
    if isinstance(value, float) and np.isnan(value): return default
    try:
        return float(value)
    except: return default

def roc_to_western_date(roc_date_str):
    if pd.isna(roc_date_str) or roc_date_str is None: return "1970-01-01"
    roc_date_str = str(roc_date_str).strip()
    try:
        if len(roc_date_str) == 7 and roc_date_str.isdigit():
            y = int(roc_date_str[:3]) + 1911
            m = int(roc_date_str[3:5])
            d = int(roc_date_str[5:])
            return f"{y}-{m:02d}-{d:02d}"
        parts = re.split(r'[/-]', roc_date_str)
        if len(parts) == 3:
            return f"{int(parts[0])+1911}-{int(parts[1]):02d}-{int(parts[2]):02d}"
    except: pass
    return roc_date_str

def convert_numeric_columns(df):
    """å°‡å­—ä¸²æ•¸å­—æ¬„ä½è½‰æ›ç‚ºæ•¸å€¼å‹æ…‹"""
    numeric_cols = ['æˆäº¤è‚¡æ•¸', 'æˆäº¤é‡‘é¡', 'æˆäº¤ç­†æ•¸', 'é–‹ç›¤åƒ¹', 'æœ€é«˜åƒ¹', 'æœ€ä½åƒ¹', 'æ”¶ç›¤åƒ¹', 'æ¼²è·Œåƒ¹å·®']
    for col in numeric_cols:
        if col in df.columns:
            # ç§»é™¤åƒåˆ†ä½é€—è™Ÿä¸¦è½‰æ›ç‚ºæ•¸å€¼
            df[col] = df[col].astype(str).str.replace(',', '').str.replace('--', '0').str.replace('X', '0')
            df[col] = pd.to_numeric(df[col], errors='coerce')
    return df

def convert_dates_to_western(df):
    """å°‡æ°‘åœ‹æ—¥æœŸè½‰æ›ç‚ºè¥¿å…ƒæ—¥æœŸ"""
    if 'æ—¥æœŸ' in df.columns:
        df['æ—¥æœŸ'] = df['æ—¥æœŸ'].apply(roc_to_western_date)
    return df

def standardize_dataframe(df, source, stock_code):
    """å°‡ DataFrame æ¬„ä½æ¨™æº–åŒ–"""
    column_mapping = {
        'æ—¥æœŸ': 'date',
        'é–‹ç›¤åƒ¹': 'open',
        'æœ€é«˜åƒ¹': 'high',
        'æœ€ä½åƒ¹': 'low',
        'æ”¶ç›¤åƒ¹': 'close',
        'æˆäº¤è‚¡æ•¸': 'volume',
        'æˆäº¤é‡‘é¡': 'amount'
    }
    # é‡æ–°å‘½åæ¬„ä½
    df = df.rename(columns=column_mapping)
    
    # åªä¿ç•™éœ€è¦çš„æ¬„ä½
    keep_cols = ['date', 'open', 'high', 'low', 'close', 'volume', 'amount']
    df = df[[col for col in keep_cols if col in df.columns]]
    
    # è¨­ç½®æ—¥æœŸç‚ºç´¢å¼•
    if 'date' in df.columns:
        df['date'] = pd.to_datetime(df['date'], errors='coerce')
        df = df.dropna(subset=['date'])
        df = df.set_index('date')
    
    # ç§»é™¤ç„¡æ•ˆè³‡æ–™
    if 'close' in df.columns:
        df = df[df['close'] > 0]
    
    return df

def read_single_key(prompt="è«‹é¸æ“‡: "):
    print(prompt, end='', flush=True)
    if HAS_TERMIOS:
        fd = sys.stdin.fileno()
        old = termios.tcgetattr(fd)
        try:
            tty.setraw(sys.stdin.fileno())
            ch = sys.stdin.read(1)
        finally:
            termios.tcsetattr(fd, termios.TCSADRAIN, old)
        print()
        return ch
    else:
        import msvcrt
        while True:
            try:
                ch = msvcrt.getch()
                if ch in [b'\x00', b'\xe0']:
                    msvcrt.getch(); continue
                decoded = ch.decode('utf-8', errors='ignore')
                if decoded:
                    print(decoded)
                    return decoded
            except: continue

def get_display_limit(default=30):
    try:
        limit = input(f"è«‹è¼¸å…¥é¡¯ç¤ºæª”æ•¸ (é è¨­{default}): ").strip()
        return int(limit) if limit.isdigit() and int(limit) > 0 else default
    except: return default

def get_volume_limit(default=500):
    try:
        limit = input(f"è«‹è¼¸å…¥æœ€å°æˆäº¤é‡(å¼µ) (é è¨­{default}): ").strip()
        return int(limit) * 1000 if limit.isdigit() else default * 1000
    except: return default * 1000

def get_correct_stock_name(code, current_name=None):
    if current_name and current_name != code and current_name != "æœªçŸ¥": return current_name
    return current_name if current_name else code

# ==============================
# æŒ‡æ¨™è¨ˆç®—é¡åˆ¥ (ä¿æŒæ•¸å­¸æ ¸å¿ƒ)
# ==============================
class IndicatorCalculator:
    @staticmethod
    def calculate_wma(series, period):
        if len(series) < period: return np.full(len(series), np.nan)
        weights = np.arange(1, period + 1)
        wma = []
        for i in range(len(series)):
            if i < period - 1: wma.append(np.nan)
            else:
                window = series[i-period+1:i+1]
                wma.append(np.dot(window, weights) / weights.sum())
        return np.array(wma)

    @staticmethod
    def calculate_wma_for_df(df, period):
        if df.empty or len(df) < period: return None
        try:
            vals = df['close'].dropna().values
            wma = IndicatorCalculator.calculate_wma(vals, period)
            return round(wma[-1], 2) if not np.isnan(wma[-1]) else None
        except: return None

    @staticmethod
    def calculate_macd_series(df, fast=12, slow=26, signal=9):
        """è¨ˆç®— MACD æŒ‡æ¨™åºåˆ—"""
        if df.empty or len(df) < slow:
            return pd.Series(np.nan, index=df.index), pd.Series(np.nan, index=df.index)
        try:
            close_prices = df['close'].values
            wma_fast = IndicatorCalculator.calculate_wma(close_prices, fast)
            wma_slow = IndicatorCalculator.calculate_wma(close_prices, slow)
            
            macd_line = wma_fast - wma_slow
            
            # è¨ˆç®—ä¿¡è™Ÿç·š
            macd_series_for_signal = []
            for i in range(len(macd_line)):
                if np.isnan(macd_line[i]):
                    macd_series_for_signal.append(np.nan)
                else:
                    macd_series_for_signal.append(macd_line[i])
            
            signal_line = IndicatorCalculator.calculate_wma(np.array(macd_series_for_signal), signal)
            
            return pd.Series(macd_line, index=df.index), pd.Series(signal_line, index=df.index)
        except:
            return pd.Series(np.nan, index=df.index), pd.Series(np.nan, index=df.index)

    @staticmethod
    def calculate_ma(df, period):
        if df.empty or len(df) < period: return None
        ma = df['close'].rolling(window=period).mean().iloc[-1]
        return round(ma, 2) if not pd.isna(ma) else None

    @staticmethod
    def calculate_rsi(df, period=14):
        if df.empty or len(df) < period + 1: return None
        try:
            deltas = np.diff(df['close'].values)
            gains = np.where(deltas > 0, deltas, 0)
            losses = np.where(deltas < 0, -deltas, 0)
            avg_gain = IndicatorCalculator.calculate_wma(gains, period)[-1]
            avg_loss = IndicatorCalculator.calculate_wma(losses, period)[-1]
            if avg_loss == 0: return 100.0 if avg_gain > 0 else 50.0
            rs = avg_gain / avg_loss
            return round(100 - (100 / (1 + rs)), 2)
        except: return None

    @staticmethod
    def calculate_rsi_series(df, period=14):
        """è¨ˆç®— RSI æŒ‡æ¨™åºåˆ—"""
        if df.empty or len(df) < period + 1:
            return pd.Series(np.nan, index=df.index)
        try:
            deltas = np.diff(df['close'].values)
            gains = np.where(deltas > 0, deltas, 0)
            losses = np.where(deltas < 0, -deltas, 0)
            
            # è£œé½Šé•·åº¦ (diff æœƒå°‘ä¸€å€‹å…ƒç´ )
            gains = np.insert(gains, 0, 0)
            losses = np.insert(losses, 0, 0)
            
            avg_gains = IndicatorCalculator.calculate_wma(gains, period)
            avg_losses = IndicatorCalculator.calculate_wma(losses, period)
            
            rsi_values = []
            for i in range(len(df)):
                if np.isnan(avg_gains[i]) or np.isnan(avg_losses[i]):
                    rsi_values.append(np.nan)
                elif avg_losses[i] == 0:
                    rsi_values.append(100.0 if avg_gains[i] > 0 else 50.0)
                else:
                    rs = avg_gains[i] / avg_losses[i]
                    rsi_values.append(100 - (100 / (1 + rs)))
            
            return pd.Series(rsi_values, index=df.index)
        except Exception as e:
            return pd.Series(np.nan, index=df.index)

    @staticmethod
    def calculate_macd(df, fast=12, slow=26, signal=9):
        if df.empty or len(df) < slow: return None, None
        try:
            closes = df['close'].values
            wma_f = IndicatorCalculator.calculate_wma(closes, fast)
            wma_s = IndicatorCalculator.calculate_wma(closes, slow)
            macd_line = wma_f - wma_s
            valid_macd = macd_line[slow-1:] 
            if len(valid_macd) < signal: return round(macd_line[-1], 2), None
            sig_vals = IndicatorCalculator.calculate_wma(valid_macd, signal)
            return round(macd_line[-1], 2), round(sig_vals[-1], 2)
        except: return None, None

    @staticmethod
    def calculate_mfi(df, period=14):
        if df.empty or len(df) < period: return pd.Series(np.nan, index=df.index)
        try:
            tp = (df['high'] + df['low'] + df['close']) / 3
            mf = tp * df['volume']
            pos = np.where(tp > tp.shift(1), mf, 0)
            neg = np.where(tp < tp.shift(1), mf, 0)
            pos_wma = IndicatorCalculator.calculate_wma(pos, period)
            neg_wma = IndicatorCalculator.calculate_wma(neg, period)
            mfi = []
            for p, n in zip(pos_wma, neg_wma):
                if np.isnan(p) or np.isnan(n): mfi.append(50.0)
                elif n == 0: mfi.append(100.0 if p > 0 else 50.0)
                else: mfi.append(100 - (100 / (1 + p/n)))
            return pd.Series(mfi, index=df.index)
        except: return pd.Series(np.full(len(df), 50.0), index=df.index)

    @staticmethod
    def calculate_vwap(df, lookback=20):
        if df.empty or len(df) < lookback: return None
        try:
            recent = df.tail(lookback)
            tp = (recent['high'] + recent['low'] + recent['close']) / 3
            return round((tp * recent['volume']).sum() / recent['volume'].sum(), 2)
        except: return None

    @staticmethod
    def calculate_vwap_series(df, lookback=20):
        """è¨ˆç®— VWAP æŒ‡æ¨™åºåˆ—"""
        if df.empty: return pd.Series(np.nan, index=df.index)
        try:
            typical_price = (df['high'] + df['low'] + df['close']) / 3
            pv = typical_price * df['volume']
            
            # ä½¿ç”¨ rolling sum è¨ˆç®—
            pv_sum = pv.rolling(window=lookback).sum()
            vol_sum = df['volume'].rolling(window=lookback).sum()
            
            vwap_series = pv_sum / vol_sum
            return vwap_series
        except:
            return pd.Series(np.nan, index=df.index)

    @staticmethod
    def calculate_chg14_series(df):
        """è¨ˆç®— 14æ—¥æ¼²è·Œå¹…åºåˆ—"""
        if df.empty: return pd.Series(np.nan, index=df.index)
        try:
            # 14æ—¥å‰çš„æ”¶ç›¤åƒ¹ (shift 14)
            prev_close = df['close'].shift(14)
            chg = (df['close'] - prev_close) / prev_close * 100
            return chg
        except:
            return pd.Series(np.nan, index=df.index)

    @staticmethod
    def calculate_chg14(df):
        if len(df) < 15: return None
        curr = df.iloc[-1]['close']
        prev = df.iloc[-15]['close']
        if prev == 0: return None
        return round((curr - prev) / prev * 100, 2)

    @staticmethod
    def calculate_vp_scheme3(df, lookback=20):
        if df.empty or len(df) < lookback: return {'POC': None, 'VP_upper': None, 'VP_lower': None}
        try:
            recent = df.tail(lookback)
            low, high = recent['low'].min(), recent['high'].max()
            if low >= high: return {'POC': None, 'VP_upper': None, 'VP_lower': None}
            bins = np.arange(low, high + 0.01, 0.01)
            vol_dist = np.zeros(len(bins))
            for _, row in recent.iterrows():
                mask = (bins >= row['low']) & (bins <= row['high'])
                cnt = mask.sum()
                if cnt > 0: vol_dist[mask] += row['volume'] / cnt
            if vol_dist.sum() == 0: return {'POC': None, 'VP_upper': None, 'VP_lower': None}
            poc_idx = np.argmax(vol_dist)
            poc = bins[poc_idx]
            sorted_idx = np.argsort(vol_dist)[::-1]
            cum_vol = 0
            total_vol = vol_dist.sum()
            va_prices = []
            for i in sorted_idx:
                cum_vol += vol_dist[i]
                va_prices.append(bins[i])
                if cum_vol >= total_vol * 0.7: break
            return {'POC': round(poc, 2), 'VP_upper': round(max(va_prices), 2), 'VP_lower': round(min(va_prices), 2)}
        except: return {'POC': None, 'VP_upper': None, 'VP_lower': None}

    @staticmethod
    def calculate_monthly_kd(df, k_period=9):
        if df.empty or len(df) < 20: return {'K': 0, 'D': 0, 'golden_cross': False}
        try:
            close_month = df['close'].rolling(20).mean()
            low_min  = df['low'].rolling(k_period).min()
            high_max = df['high'].rolling(k_period).max()
            rsv = (close_month - low_min) / (high_max - low_min) * 100
            rsv = rsv.fillna(50)
            k = rsv.ewm(com=2).mean()
            d = k.ewm(com=2).mean()
            if len(k) < 2 or len(d) < 2:
                return {'K': round(k.iloc[-1],2), 'D': round(d.iloc[-1],2), 'golden_cross': False}
            cross = (k.iloc[-2] < d.iloc[-2]) and (k.iloc[-1] >= d.iloc[-1])
            return {'K': round(k.iloc[-1],2), 'D': round(d.iloc[-1],2), 'golden_cross': cross}
        except: return {'K': 0, 'D': 0, 'golden_cross': False}

    @staticmethod

    @staticmethod
    def calculate_daily_kd_series(df, n=9):
        """è¨ˆç®—æ—¥KDæŒ‡æ¨™ (å›å‚³ Series)"""
        try:
            high = df['high']
            low = df['low']
            close = df['close']
            
            # RSV = (Close - Lowest_Low_9) / (Highest_High_9 - Lowest_Low_9) * 100
            lowest_low = low.rolling(window=n, min_periods=1).min()
            highest_high = high.rolling(window=n, min_periods=1).max()
            rsv = (close - lowest_low) / (highest_high - lowest_low) * 100
            rsv = rsv.fillna(50) # ç¼ºå€¼è£œ50
            
            # K = 2/3 * Prev_K + 1/3 * RSV
            # D = 2/3 * Prev_D + 1/3 * K
            k_series = []
            d_series = []
            k_curr = 50
            d_curr = 50
            
            for val in rsv:
                k_curr = (2/3) * k_curr + (1/3) * val
                d_curr = (2/3) * d_curr + (1/3) * k_curr
                k_series.append(k_curr)
                d_series.append(d_curr)
                
            return pd.Series(k_series, index=df.index), pd.Series(d_series, index=df.index)
        except Exception as e:
            # print(f"Daily KD Error: {e}")
            return pd.Series([None]*len(df), index=df.index), pd.Series([None]*len(df), index=df.index)

    @staticmethod
    def resample_to_weekly(df):
        """å°‡æ—¥ç·šæ•¸æ“šè½‰æ›ç‚ºå‘¨ç·šæ•¸æ“š"""
        try:
            # ç¢ºä¿ç´¢å¼•æ˜¯ DatetimeIndex
            df_copy = df.copy()
            df_copy.index = pd.to_datetime(df_copy['date'])
            
            # Resample logic
            weekly = df_copy.resample('W-FRI').agg({
                'open': 'first',
                'high': 'max',
                'low': 'min',
                'close': 'last',
                'volume': 'sum'
            })
            return weekly.dropna()
        except Exception as e:
            # print(f"Resample Error: {e}")
            return pd.DataFrame()

    @staticmethod
    def calculate_weekly_kd_series(df, n=9):
        """è¨ˆç®—å‘¨KDæŒ‡æ¨™ (å›å‚³ Seriesï¼Œå·²å°é½Šæ—¥ç·š)"""
        try:
            # 1. è½‰å‘¨ç·š
            weekly_df = IndicatorCalculator.resample_to_weekly(df)
            if weekly_df.empty or len(weekly_df) < n:
                return pd.Series([None]*len(df), index=df.index), pd.Series([None]*len(df), index=df.index)
            
            # 2. è¨ˆç®—å‘¨KD
            wk, wd = IndicatorCalculator.calculate_daily_kd_series(weekly_df, n) # é‚è¼¯ç›¸åŒ
            
            # 3. å°‡å‘¨KDå›å¡«åˆ°æ—¥ç·š (ä½¿ç”¨ reindex + ffill)
            # æ³¨æ„ï¼šweekly_df çš„ index æ˜¯æ¯å‘¨äº”ï¼Œæˆ‘å€‘éœ€è¦å°‡å…¶æ˜ å°„å›æ—¥ç·š
            # ä½¿ç”¨ asof æˆ– merge_asof å¯èƒ½æ›´æº–ç¢ºï¼Œä½†é€™è£¡ç°¡å–®ç”¨ reindex
            
            # å»ºç«‹ä¸€å€‹åŒ…å«æ‰€æœ‰æ—¥æœŸçš„ DataFrame
            df_dates = pd.DataFrame(index=pd.to_datetime(df['date']))
            
            # å°‡å‘¨ç·šæ•¸æ“šåˆä½µé€²ä¾†
            wk.name = 'week_k'
            wd.name = 'week_d'
            
            merged = df_dates.join(wk, how='left').join(wd, how='left')
            
            # å‘å‰å¡«å…… (æœ¬å‘¨äº”çš„å€¼åœ¨ä¸‹å‘¨äº”å‡ºä¾†å‰éƒ½æœ‰æ•ˆï¼Ÿæˆ–è€…è©²å‘¨æ¯å¤©éƒ½ç”¨è©²å‘¨äº”çš„å€¼ï¼Ÿ)
            # å‚³çµ±ä¸Šï¼Œå‘¨KDæ˜¯è©²å‘¨çµæŸæ‰ç¢ºå®šã€‚ä½†åœ¨é€²è¡Œä¸­ï¼Œé€šå¸¸ç”¨ç•¶å‰è¨ˆç®—å€¼ã€‚
            # é€™è£¡ç°¡å–®è™•ç†ï¼šffill (éå»çš„å€¼å»¶çºŒ)
            merged = merged.fillna(method='ffill')
            
            return merged['week_k'].values, merged['week_d'].values
            
        except Exception as e:
            # print(f"Weekly KD Error: {e}")
            return pd.Series([None]*len(df), index=df.index), pd.Series([None]*len(df), index=df.index)


    @staticmethod
    def calculate_smi_series(df, period=14):
        """è¨ˆç®— Smart Money Index (SMI)"""
        try:
            # ç°¡åŒ–ç‰ˆ SMI: (æ”¶ç›¤ - é–‹ç›¤) / (æœ€é«˜ - æœ€ä½) çš„ç´¯è¨ˆ
            # çœŸæ­£çš„ SMI éœ€è¦åˆ†æ™‚è³‡æ–™ï¼Œé€™è£¡ç”¨æ—¥ç·šæ¨¡æ“¬
            # æ¦‚å¿µ: æ”¶ç›¤ > é–‹ç›¤ ä»£è¡¨æ•£æˆ¶è¿½é«˜? ä¸ï¼Œé€šå¸¸ Intraday Momentum Index 
            # é€™è£¡æ¡ç”¨: 
            # Smart Money = (Close - Low) - (High - Close) = 2*Close - High - Low
            # SMI = EMA(Smart Money, period)
            
            high = df['high']
            low = df['low']
            close = df['close']
            
            # Smart Money Flow
            smf = (2 * close) - high - low
            
            # SMI
            smi = smf.ewm(span=period, adjust=False).mean()
            return smi
        except:
            return pd.Series(0, index=df.index)

    @staticmethod
    def calculate_nvi_series(df):
        """è¨ˆç®— Negative Volume Index (NVI)"""
        try:
            close = df['close']
            volume = df['volume']
            
            nvi = pd.Series(1000.0, index=df.index)
            
            for i in range(1, len(df)):
                if volume.iloc[i] < volume.iloc[i-1]:
                    # æˆäº¤é‡ç¸®å°ï¼Œè°æ˜éŒ¢é€²å ´?
                    pct_change = (close.iloc[i] - close.iloc[i-1]) / close.iloc[i-1]
                    nvi.iloc[i] = nvi.iloc[i-1] * (1 + pct_change)
                else:
                    nvi.iloc[i] = nvi.iloc[i-1]
            
            # åŠ ä¸Š EMA è¨Šè™Ÿç·š
            # ä¿®æ­£: æ”¹ç‚º 200 å¤© EMAï¼ˆå°æ‡‰ WMA200ï¼‰
            nvi_ema = nvi.ewm(span=200, adjust=False).mean()
            return nvi, nvi_ema
        except:
            return pd.Series(1000.0, index=df.index), pd.Series(1000.0, index=df.index)

    @staticmethod
    def calculate_vsa_signal_series(df):
        """è¨ˆç®— VSA (Volume Spread Analysis) è¨Šè™Ÿ"""
        try:
            # ç°¡å–® VSA é‚è¼¯:
            # 1. åœæ­¢è¡Œç‚º (Stopping Volume): ä¸‹è·Œè¶¨å‹¢ä¸­ + çˆ†é‡ + æ”¶ä¸‹å½±ç·š
            # 2. åŠªåŠ›ç„¡æœ (Effort No Result): ä¸Šæ¼²è¶¨å‹¢ä¸­ + çˆ†é‡ + æ”¶ä¸Šå½±ç·š/å°å¯¦é«”
            
            signals = pd.Series(0, index=df.index)
            
            close = df['close']
            high = df['high']
            low = df['low']
            open_ = df['open']
            volume = df['volume']
            
            vol_ma = volume.rolling(20).mean()
            spread = high - low
            avg_spread = spread.rolling(20).mean()
            
            # å‘é‡åŒ–è¨ˆç®—
            is_high_vol = volume > (vol_ma * 1.5)
            is_wide_spread = spread > (avg_spread * 1.2)
            is_down_bar = close < close.shift(1)
            is_up_bar = close > close.shift(1)
            
            # Stopping Volume (è¨Šè™Ÿ 1)
            # ä¸‹è·Œ + çˆ†é‡ + æ”¶ç›¤åœ¨ä¸‹åŠéƒ¨ä½†æœ‰æ”¯æ’ (é€™è£¡ç°¡åŒ–ç‚ºæ”¶ç›¤é›¢ä½é»æœ‰æ®µè·é›¢)
            # ä¿®æ­£: Stopping Volume é€šå¸¸æ˜¯æ”¶ç›¤åœ¨ç›¸å°é«˜ä½ (æ”¶è…³)
            # ä¿®æ­£: å®‰å…¨è¨ˆç®— close_posï¼Œé¿å…é™¤ä»¥é›¶
            denominator = high - low
            close_pos = pd.Series(
                np.where(
                    denominator > 0.0001,
                    (close - low) / denominator,
                    0.5  # ç•¶ high == low æ™‚è¨­ç‚ºä¸­æ€§å€¼
                ),
                index=df.index
            )
            
            cond_stopping = is_down_bar & is_high_vol & (close_pos > 0.6)
            signals[cond_stopping] = 1
            
            # No Demand (è¨Šè™Ÿ 2)
            # ä¸Šæ¼² + é‡ç¸® + çª„å¹…
            cond_no_demand = is_up_bar & (volume < vol_ma * 0.8) & (spread < avg_spread * 0.8)
            signals[cond_no_demand] = 2
            
            return signals
        except:
            return pd.Series(0, index=df.index)

    @staticmethod
    def calculate_smart_score_series(df):
        """è¨ˆç®—ç¶œåˆ Smart Score (0-5åˆ†)"""
        try:
            # 1. SMI
            smi = IndicatorCalculator.calculate_smi_series(df)
            smi_signal = (smi > smi.shift(1)).astype(int)
            
            # 2. NVI
            nvi, nvi_ema = IndicatorCalculator.calculate_nvi_series(df)
            nvi_signal = (nvi > nvi_ema).astype(int)
            
            # 3. VSA
            vsa_signal = IndicatorCalculator.calculate_vsa_signal_series(df)
            
            # 4. SVI (Smart Volume Index) - ç°¡åŒ–ç‰ˆ: é‡ç¸®åƒ¹æ¼² or é‡å¢åƒ¹è·Œ(å¸ç±Œ?)
            # é€™è£¡ç”¨: åƒ¹æ¼²é‡ç¸® (æƒœå”®) = 1
            close_up = df['close'] > df['close'].shift(1)
            vol_down = df['volume'] < df['volume'].shift(1)
            svi_signal = (close_up & vol_down).astype(int)
            
            # 5. ç¶œåˆè©•åˆ†
            # åŸºç¤åˆ†: è¶¨å‹¢å‘ä¸Š (MA20 > MA60)
            ma20 = df['close'].rolling(20).mean()
            ma60 = df['close'].rolling(60).mean()
            trend_score = (ma20 > ma60).astype(int)
            
            # ç¸½åˆ†
            total_score = smi_signal + nvi_signal + (vsa_signal > 0).astype(int) + svi_signal + trend_score
            
            return total_score, smi_signal, nvi_signal, vsa_signal, svi_signal
        except Exception as e:
            print(f"Smart Score Calc Error: {e}")
            idx = df.index
            return (pd.Series(0, index=idx), pd.Series(0, index=idx), 
                    pd.Series(0, index=idx), pd.Series(0, index=idx), pd.Series(0, index=idx))

    def calculate_monthly_kd_series(df, k_period=9):
        """è¨ˆç®—æœˆKDæŒ‡æ¨™åºåˆ— (ä¿®æ­£: è¿”å› Series)"""
        if df.empty or len(df) < 20: 
            return pd.Series(0, index=df.index), pd.Series(0, index=df.index)
        try:
            close_month = df['close'].rolling(20).mean()
            low_min  = df['low'].rolling(k_period).min()
            high_max = df['high'].rolling(k_period).max()
            
            # [ä¿®æ­£] è™•ç†åˆ†æ¯ç‚º 0 çš„æƒ…æ³ (High == Low)
            denominator = high_max - low_min
            denominator = denominator.replace(0, np.nan)
            
            rsv = (close_month - low_min) / denominator * 100
            
            # [ä¿®æ­£] å¼·åˆ¶é™åˆ¶ RSV åœ¨ 0~100 ä¹‹é–“ (é¿å… MA20 è¶…å‡º High/Low ç¯„åœå°è‡´æ•¸å€¼ç•°å¸¸)
            rsv = rsv.clip(0, 100)
            
            rsv = rsv.fillna(50)
            k = rsv.ewm(com=2).mean()
            d = k.ewm(com=2).mean()
            return k, d
        except: 
            return pd.Series(0, index=df.index), pd.Series(0, index=df.index)

# ==============================
# æ­¥é©Ÿå‡½æ•¸
# ==============================
def get_latest_market_date():
    """ç²å–å¸‚å ´æœ€æ–°äº¤æ˜“æ—¥æœŸ (æ¯”å° TWSE èˆ‡ TPEx)"""
    dates = []
    
    # 1. Check TWSE (Website API)
    try:
        url = f"{TWSE_STOCK_DAY_ALL_URL}&_={int(time.time())}"
        session = requests.Session()
        session.headers.update({
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
            'Referer': 'https://www.twse.com.tw/zh/page/trading/exchange/STOCK_DAY_ALL.html'
        })
        try:
            session.get('https://www.twse.com.tw/zh/page/trading/exchange/STOCK_DAY_ALL.html', timeout=5, verify=False)
        except: pass
        
        res = session.get(url, timeout=10, verify=False)
        if res.status_code == 200:
            data = res.json()
            if 'date' in data and len(data['date']) == 8:
                d = data['date'] # YYYYMMDD
                dates.append(f"{d[:4]}-{d[4:6]}-{d[6:]}")
    except: pass
    
    # 2. Check TPEx
    try:
        url = f"{TPEX_DAILY_TRADING_URL}?d=&stk_code=&o=json&_={int(time.time())}"
        res = requests.get(url, timeout=10, verify=False)
        if res.status_code == 200:
            data = res.json()
            if 'reportDate' in data:
                dates.append(roc_to_western_date(data['reportDate']))
            elif 'aaData' in data and data['aaData']:
                pass
    except: pass
    
    if not dates:
        return datetime.now().strftime("%Y-%m-%d")
        
    return max(dates)

def step1_fetch_stock_list():
    print_flush("\n[Step 1] æ›´æ–°ä¸Šå¸‚æ«ƒæ¸…å–®...")
    stocks = []
    try:
        print_flush("  -> ä¸‹è¼‰ TWSE...", end="")
        res = requests.get(TWSE_BWIBBU_URL, timeout=30, verify=False)
        for i in res.json():
            if is_normal_stock(i.get('Code'), i.get('Name')):
                stocks.append({'code': i['Code'], 'name': i['Name'], 'market': 'TWSE'})
        print_flush(" âœ“")
    except: print_flush(" âœ—")
    try:
        print_flush("  -> ä¸‹è¼‰ TPEx...", end="")
        res = requests.get(TPEX_MAINBOARD_URL, timeout=30, verify=False)
        for i in res.json():
            if is_normal_stock(i.get('SecuritiesCompanyCode'), i.get('CompanyName')):
                stocks.append({'code': i['SecuritiesCompanyCode'], 'name': i['CompanyName'], 'market': 'TPEX'})
        print_flush(" âœ“")
    except: print_flush(" âœ—")

    if stocks:
        pd.DataFrame(stocks).to_csv(STOCK_LIST_PATH, index=False)
        print_flush(f"âœ“ å·²æ›´æ–° {len(stocks)} æª”è‚¡ç¥¨è‡³æ¸…å–®")
    else:
        print_flush("âŒ æ›´æ–°å¤±æ•—")

def step2_download_tpex_daily():
    print_flush("\n[Step 2] ä¸‹è¼‰ TPEx (ä¸Šæ«ƒ) æœ¬æ—¥è¡Œæƒ…...")
    try:
        res = requests.get(TPEX_MAINBOARD_URL, timeout=30, verify=False)
        data = res.json()
        if not data: return
        trade_date = roc_to_western_date(data[0].get('Date') or data[0].get('date'))
        print_flush(f"  -> æ—¥æœŸ: {trade_date}")
        
        new_count = 0
        update_count = 0
        skip_count = 0
        
        updated_codes = set()
        with db_manager.get_connection() as conn:
            cur = conn.cursor()
            for item in data:
                code = item.get('SecuritiesCompanyCode', '').strip()
                name = item.get('CompanyName', '').strip()
                if not is_normal_stock(code, name): continue
                
                close = safe_num(item.get('Close'))
                vol = safe_int(item.get('TradingShares'))
                
                # æª¢æŸ¥æ˜¯å¦å­˜åœ¨
                cur.execute("SELECT close FROM stock_data WHERE code=? AND date=?", (code, trade_date))
                existing = cur.fetchone()
                
                should_update = False
                if existing is None:
                    new_count += 1
                    should_update = True
                elif existing[0] != close:
                    update_count += 1
                    should_update = True
                else:
                    skip_count += 1
                
                if should_update:
                    updated_codes.add(code)
                    cur.execute("SELECT close, volume FROM stock_data WHERE code=? AND date<? ORDER BY date DESC LIMIT 1", (code, trade_date))
                    prev = cur.fetchone()
                    pc, pv = (prev[0], prev[1]) if prev else (close, vol)
                    
                    cur.execute("""
                        INSERT OR REPLACE INTO stock_data 
                        (code, name, date, open, high, low, close, volume, close_prev, vol_prev)
                        VALUES (?,?,?,?,?,?,?,?,?,?)
                    """, (code, name, trade_date, safe_num(item.get('Open')), safe_num(item.get('High')), safe_num(item.get('Low')), close, vol, pc, pv))
            conn.commit()
        print_flush(f"âœ“ TPEx æ›´æ–°: æ–°å¢ {new_count} ç­† | æ›´æ–° {update_count} ç­† | è·³é {skip_count} ç­†")
        return updated_codes
    except Exception as e: 
        print_flush(f"âŒ å¤±æ•—: {e}")
        return set()

def step3_download_twse_daily():
    print_flush("\n[Step 3] ä¸‹è¼‰ TWSE (ä¸Šå¸‚) æœ¬æ—¥è¡Œæƒ…...")
    try:
        # ä½¿ç”¨ Session ä¿æŒé€£ç·šèˆ‡ Cookies
        session = requests.Session()
        session.headers.update({
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
            'Accept': 'application/json, text/javascript, */*; q=0.01',
            'Accept-Language': 'zh-TW,zh;q=0.9,en-US;q=0.8,en;q=0.7',
            'Referer': 'https://www.twse.com.tw/zh/page/trading/exchange/STOCK_DAY_ALL.html',
            'X-Requested-With': 'XMLHttpRequest'
        })
        
        # å…ˆè¨ªå•é¦–é å–å¾— Cookies
        try:
            session.get('https://www.twse.com.tw/zh/page/trading/exchange/STOCK_DAY_ALL.html', timeout=10, verify=False)
        except: pass
        
        # å†è«‹æ±‚è³‡æ–™
        url = f"{TWSE_STOCK_DAY_ALL_URL}&_={int(time.time())}"
        res = session.get(url, timeout=30, verify=False)
        try:
            data = res.json()
        except json.JSONDecodeError:
            print_flush(f"âŒ TWSE å›æ‡‰é JSON æ ¼å¼: {res.text[:100]}...")
            return
            
        if not data or 'data' not in data: return
        
        # Website API date format: YYYYMMDD
        raw_date = data.get('date', '')
        if len(raw_date) == 8:
            trade_date = f"{raw_date[:4]}-{raw_date[4:6]}-{raw_date[6:]}"
        else:
            trade_date = datetime.now().strftime("%Y-%m-%d")
            
        print_flush(f"  -> æ—¥æœŸ: {trade_date}")

        new_count = 0
        update_count = 0
        skip_count = 0

        updated_codes = set()
        with db_manager.get_connection() as conn:
            cur = conn.cursor()
            # Website API data structure: List of Lists
            # Indices: 0=Code, 1=Name, 2=Vol, 3=Val, 4=Open, 5=High, 6=Low, 7=Close, 8=Change, 9=Trans
            for item in data['data']:
                if len(item) < 8: continue
                code = item[0].strip()
                name = item[1].strip()
                if not is_normal_stock(code, name): continue
                
                close = safe_num(item[7])
                vol = safe_int(item[2])
                
                # æª¢æŸ¥æ˜¯å¦å­˜åœ¨
                cur.execute("SELECT close FROM stock_data WHERE code=? AND date=?", (code, trade_date))
                existing = cur.fetchone()
                
                should_update = False
                if existing is None:
                    new_count += 1
                    should_update = True
                elif existing[0] != close:
                    update_count += 1
                    should_update = True
                else:
                    skip_count += 1
                
                if should_update:
                    updated_codes.add(code)
                    cur.execute("SELECT close, volume FROM stock_data WHERE code=? AND date<? ORDER BY date DESC LIMIT 1", (code, trade_date))
                    prev = cur.fetchone()
                    pc, pv = (prev[0], prev[1]) if prev else (close, vol)
                    
                    cur.execute("""
                        INSERT OR REPLACE INTO stock_data 
                        (code, name, date, open, high, low, close, volume, close_prev, vol_prev)
                        VALUES (?,?,?,?,?,?,?,?,?,?)
                    """, (code, name, trade_date, safe_num(item[4]), safe_num(item[5]), safe_num(item[6]), close, vol, pc, pv))
            conn.commit()
        print_flush(f"âœ“ TWSE æ›´æ–°: æ–°å¢ {new_count} ç­† | æ›´æ–° {update_count} ç­† | è·³é {skip_count} ç­†")
        return updated_codes
    except Exception as e: 
        print_flush(f"âŒ å¤±æ•—: {e}")
        return set()

MIN_DATA_COUNT = 450

def step4_check_data_gaps():
    print_flush("\n[Step 4] æª¢æŸ¥æ•¸æ“šç¼ºå¤±...")
    with db_manager.get_connection() as conn:
        cur = conn.cursor()
        rows = cur.execute("SELECT code, COUNT(*) as cnt FROM stock_data GROUP BY code").fetchall()
        
    gaps = [r for r in rows if r[1] < MIN_DATA_COUNT]
    if not gaps:
        print_flush(f"âœ“ æ‰€æœ‰è‚¡ç¥¨è³‡æ–™çš†å……è¶³ (>= {MIN_DATA_COUNT} ç­†)")
    else:
        print_flush(f"âš  ç™¼ç¾ {len(gaps)} æª”è‚¡ç¥¨è³‡æ–™ä¸è¶³:")
        for r in gaps[:5]:
            print_flush(f"  - {r[0]}: {r[1]} ç­†")
        if len(gaps) > 5: print_flush(f"  ... ç­‰å…± {len(gaps)} æª”")

def step5_clean_delisted():
    print_flush("\n[Step 5] æ¸…ç†ä¸‹å¸‚è‚¡ç¥¨...")
    if not STOCK_LIST_PATH.exists():
        print_flush("âš  æ‰¾ä¸åˆ°è‚¡ç¥¨æ¸…å–®ï¼Œè·³éæ¸…ç†")
        return
        
    try:
        df = pd.read_csv(STOCK_LIST_PATH)
        valid_codes = set(df['code'].astype(str))
        
        with db_manager.get_connection() as conn:
            cur = conn.cursor()
            db_codes = set(row[0] for row in cur.execute("SELECT DISTINCT code FROM stock_data").fetchall())
            
            delisted = db_codes - valid_codes
            if delisted:
                print_flush(f"ç™¼ç¾ {len(delisted)} æª”ä¸‹å¸‚è‚¡ç¥¨ï¼Œæº–å‚™æ¸…ç†...")
                for code in delisted:
                    cur.execute("DELETE FROM stock_data WHERE code=?", (code,))
                conn.commit()
                print_flush(f"âœ“ å·²æ¸…é™¤ {len(delisted)} æª”ä¸‹å¸‚è‚¡ç¥¨è³‡æ–™")
            else:
                print_flush("âœ“ ç„¡ä¸‹å¸‚è‚¡ç¥¨æ®˜ç•™")
                
    except Exception as e:
        print_flush(f"âŒ æ¸…ç†å¤±æ•—: {e}")

def step4_load_data():
    print_flush("\n[Step 4] è¼‰å…¥åˆ†æè³‡æ–™...")
    data = {}
    with db_manager.get_connection() as conn:
        conn.row_factory = sqlite3.Row
        cur = conn.cursor()
        rows = cur.execute("""
            SELECT T1.* FROM stock_data T1
            JOIN (SELECT code, MAX(date) as max_date FROM stock_data GROUP BY code) T2 
            ON T1.code = T2.code AND T1.date = T2.max_date
        """).fetchall()
        
        for row in rows:
            data[row['code']] = dict(row)
            
    print_flush(f"âœ“ å·²è¼‰å…¥ {len(data)} æª”è‚¡ç¥¨è³‡æ–™")
    return data
def reset_color():
    return '\033[0m'

def get_volume_color(vol_ratio):
    """æˆäº¤é‡å°ˆç”¨: å€æ•¸ >1 ç´…(å¢é‡), <=1 ç¶ (ç¸®é‡)"""
    return '\033[91m' if vol_ratio > 1.0 else '\033[92m'

def get_trend_color(current, previous):
    """è¶¨å‹¢å°ˆç”¨: ä¸Šæšç´…, ä¸‹è·Œç¶ , å¹³ç›¤ç™½"""
    if current is None or previous is None:
        return '\033[0m'
    return '\033[91m' if current > previous else ('\033[92m' if current < previous else '\033[0m')

def get_arrow(today_val, prev_val):
    if today_val is None or prev_val is None:
        return " "
    if today_val > prev_val:
        return "â†‘"
    elif today_val < prev_val:
        return "â†“"
    else:
        return " "

def get_colored_value(value, change, arrow=None):
    """æ ¹æ“šæ¼²è·Œè¿”å›å¸¶é¡è‰²çš„å€¼å’Œç®­é ­"""
    color = get_color_code(change)
    
    if isinstance(value, (int, float)):
        val_str = f"{value:.2f}"
    else:
        val_str = str(value)
        
    if arrow:
        return f"{color}{arrow}{val_str}{reset_color()}"
    return f"{color}{val_str}{reset_color()}"

# Helper Functions for Formatting
def get_color_code(val):
    if val is None: return ""
    if val > 0: return "\033[91m" # Red
    if val < 0: return "\033[92m" # Green
    return "\033[97m" # White

def reset_color():
    return "\033[0m"

def get_arrow(curr, prev):
    if curr is None or prev is None: return ""
    if curr > prev: return "â†‘"
    if curr < prev: return "â†“"
    return "-"

def get_volume_color(ratio):
    if ratio >= 2.0: return "\033[95m" # Magenta
    if ratio >= 1.5: return "\033[91m" # Red
    if ratio >= 1.2: return "\033[93m" # Yellow
    return "\033[97m"

def get_colored_value(text, change, arrow):
    color = get_color_code(change)
    return f"{color}{text}{arrow}{reset_color()}"

def get_trend_color(curr, prev):
    if curr is None or prev is None: return ""
    if curr > prev: return "\033[91m"
    if curr < prev: return "\033[92m"
    return "\033[97m"

def safe_float_preserving_none(value):
    if value is None: return None
    try:
        return float(value)
    except:
        return None

def format_scan_result(code, name, indicators, show_date=False):
    """æ ¼å¼åŒ–å–®æ—¥æŠ€è¡“æŒ‡æ¨™ - ä¿®æ­£: Null é˜²ç¦¦"""
    if not indicators:
        return ""
    
    def safe_display(value, prefix="", suffix="", default="N/A"):
        """å®‰å…¨æ ¼å¼åŒ– - None é¡¯ç¤º N/A"""
        if value is None:
            return f"{prefix}{default}{suffix}"
        return f"{prefix}{value}{suffix}"
    
    def safe_float(value, default=0.0):
        if value is None:
            return default
        try:
            return float(value)
        except (ValueError, TypeError):
            return default
    
    date = indicators.get('date', '')
    close = safe_float(indicators.get('close'))
    close_prev = safe_float(indicators.get('close_prev'))
    volume = safe_float(indicators.get('volume'))
    vol_prev = safe_float(indicators.get('vol_prev'))
    mfi = safe_float(indicators.get('mfi14') or indicators.get('MFI'))
    mfi_prev = safe_float(indicators.get('mfi14_prev') or indicators.get('MFI_prev'))
    chg14 = safe_float(indicators.get('chg14_pct') or indicators.get('CHG14'))
    chg14_prev = safe_float(indicators.get('chg14_pct_prev') or indicators.get('CHG14_prev'))
    poc = safe_float(indicators.get('vp_poc') or indicators.get('POC'))
    vp_upper = safe_float(indicators.get('vp_upper') or indicators.get('VP_upper'))
    vp_lower = safe_float(indicators.get('vp_lower') or indicators.get('VP_lower'))
    vwap = safe_float(indicators.get('vwap20') or indicators.get('VWAP'))
    vwap_prev = safe_float(indicators.get('vwap20_prev') or indicators.get('VWAP_prev'))
    
    # ä¿®å¾©: ä½¿ç”¨ safe_float_preserving_none ä¿ç•™ Noneï¼Œè®“ç®­é ­åˆ¤æ–·æ­£ç¢º
    ma3 = safe_float_preserving_none(indicators.get('ma3') or indicators.get('MA3'))
    ma3_prev = safe_float_preserving_none(indicators.get('ma3_prev') or indicators.get('MA3_prev'))
    ma20 = safe_float_preserving_none(indicators.get('ma20') or indicators.get('MA20'))
    ma20_prev = safe_float_preserving_none(indicators.get('ma20_prev') or indicators.get('MA20_prev'))
    ma60 = safe_float_preserving_none(indicators.get('ma60') or indicators.get('MA60'))
    ma60_prev = safe_float_preserving_none(indicators.get('ma60_prev') or indicators.get('MA60_prev'))
    ma200 = safe_float_preserving_none(indicators.get('ma200') or indicators.get('MA200'))
    ma200_prev = safe_float_preserving_none(indicators.get('ma200_prev') or indicators.get('MA200_prev'))
    
    change_pct = 0
    if close_prev and close_prev != 0:
        change_pct = (close - close_prev) / close_prev * 100
    
    # ä¿®æ­£æˆäº¤é‡æ¯”å€¼è¨ˆç®—
    if vol_prev and vol_prev > 0:
        volume_ratio = volume / vol_prev
    else:
        volume_ratio = 1.0  # æ”¹ç‚º1.0è¡¨ç¤ºç„¡è®ŠåŒ–,è€Œé0
    
    color = get_color_code(change_pct)
    reset = reset_color()
    
    vol_in_lots = volume / 1000 if volume else 0
    
    mfi_change = mfi - mfi_prev if mfi is not None and mfi_prev is not None else 0
    chg14_change = chg14 - chg14_prev if chg14 is not None and chg14_prev is not None else 0
    vwap_change = vwap - vwap_prev if vwap is not None and vwap_prev is not None else 0
    
    mfi_arrow = get_arrow(mfi, mfi_prev)
    chg14_arrow = get_arrow(chg14, chg14_prev)
    vwap_arrow = get_arrow(vwap, vwap_prev)
    
    vol_color = get_volume_color(volume_ratio)
    vol_text = f"{vol_color}{volume_ratio:.1f}å€{reset_color()}"
    colored_volume_ratio = vol_text
    
    colored_mfi = get_colored_value(f"{mfi:.1f}", mfi_change, mfi_arrow)
    colored_chg14 = get_colored_value(f"{chg14:.1f}%", chg14_change, chg14_arrow)
    colored_vwap = get_colored_value(f"{vwap:.2f}", vwap_change, vwap_arrow)
    
    ma3_color = get_trend_color(ma3, ma3_prev)
    colored_ma3 = safe_display(ma3, prefix=ma3_color, suffix=reset_color())

    ma20_color = get_trend_color(ma20, ma20_prev)
    colored_ma20 = safe_display(ma20, prefix=ma20_color, suffix=reset_color())
    
    ma60_color = get_trend_color(ma60, ma60_prev)
    colored_ma60 = safe_display(ma60, prefix=ma60_color, suffix=reset_color())

    ma200_color = get_trend_color(ma200, ma200_prev)
    colored_ma200 = safe_display(ma200, prefix=ma200_color, suffix=reset_color())
    
    if show_date:
        line1 = f"{date} {name}({code}) æˆäº¤é‡:{vol_in_lots:,.0f}å¼µ({colored_volume_ratio}) MFI:{colored_mfi}"
    else:
        line1 = f"{name}({code}) æˆäº¤é‡:{vol_in_lots:,.0f}å¼µ({colored_volume_ratio}) MFI:{colored_mfi}"
    
    line2 = f"æ”¶ç›¤åƒ¹:{color}{close:.2f}({change_pct:+.2f}%){reset} POC:{poc:.2f} 14æ—¥:{colored_chg14}"
    
    # æœˆKD é»ƒé‡‘äº¤å‰æç¤º
    if indicators.get('KD_GOLDEN_CROSS'):
        line2 += f"  {get_color_code(+1)}âœ… K={indicators['KD_K']:.2f} D={indicators['KD_D']:.2f}{reset_color()}"
        
    line3 = f"VPä¸Š:{COFFEE_COLOR}{vp_upper:.2f}{reset} VWAP:{colored_vwap} VPä¸‹:{COFFEE_COLOR}{vp_lower:.2f}{reset}"
    line4 = f"MA3:{colored_ma3} MA20:{colored_ma20} MA60:{colored_ma60} MA200:{colored_ma200}"
    
    return f"{line1}\n{line2}\n{line3}\n{line4}"

def format_scan_result_list(code, name, indicators_list):
    # æ ¼å¼åŒ–å¤šå¤©æŠ€è¡“æŒ‡æ¨™çµæœ
    if not indicators_list:
        return ""
    output_lines = []
    for indicators in indicators_list:
        output_lines.append(format_scan_result(code, name, indicators, show_date=True))
    return "\n".join(output_lines)

# ==============================
# é›²ç«¯åŒæ­¥ç®¡ç†å™¨
# ==============================

class CloudSync:
    """Supabase é›²ç«¯åŒæ­¥ç®¡ç†å™¨"""
    
    @staticmethod
    def get_headers():
        return {
            "apikey": SUPABASE_KEY,
            "Authorization": f"Bearer {SUPABASE_KEY}",
            "Content-Type": "application/json",
            "Prefer": "resolution=merge-duplicates" # ç”¨æ–¼ upsert
        }

    @staticmethod
    def upload_stock_list():
        """ä¸Šå‚³è‚¡ç¥¨æ¸…å–®åˆ°é›²ç«¯"""
        if not ENABLE_CLOUD_SYNC:
            print_flush("âš  æœªè¨­å®š Supabaseï¼Œç„¡æ³•åŒæ­¥")
            return False
            
        print_flush("â˜ æ­£åœ¨ä¸Šå‚³è‚¡ç¥¨æ¸…å–®åˆ°é›²ç«¯...")
        try:
            df = pd.read_csv(STOCK_LIST_PATH, dtype=str)
            records = []
            for _, row in df.iterrows():
                records.append({
                    "code": row['code'],
                    "name": row['name'],
                    "market_type": row.get('market', 'æœªçŸ¥')
                })
            
            # åˆ†æ‰¹ä¸Šå‚³
            batch_size = 100
            total = len(records)
            for i in range(0, total, batch_size):
                batch = records[i:i+batch_size]
                url = f"{SUPABASE_URL}/rest/v1/stock_list"
                response = requests.post(url, headers=CloudSync.get_headers(), json=batch, verify=False)
                if response.status_code not in [200, 201]:
                    print_flush(f"âš  ä¸Šå‚³å¤±æ•— (æ‰¹æ¬¡ {i}): {response.text}")
                print_flush(f"\ré€²åº¦: {min(i+batch_size, total)}/{total}", end="")
            
            print_flush("\nâœ“ è‚¡ç¥¨æ¸…å–®ä¸Šå‚³å®Œæˆ")
            return True
        except Exception as e:
            print_flush(f"\nâŒ ä¸Šå‚³éŒ¯èª¤: {e}")
            return False

    @staticmethod
    def upload_calculated_data(days=None):
        """ä¸Šå‚³è¨ˆç®—çµæœåˆ°é›²ç«¯ (days=None ç‚ºå…¨éƒ¨)"""
        if not ENABLE_CLOUD_SYNC:
            print_flush("âš  æœªè¨­å®š Supabaseï¼Œç„¡æ³•åŒæ­¥")
            return False
            
        range_str = f"æœ€è¿‘ {days} å¤©" if days else "æ‰€æœ‰"
        print_flush(f"â˜ æ­£åœ¨ä¸Šå‚³ {range_str} æ•¸æ“šåˆ°é›²ç«¯...")
        try:
            with db_manager.get_connection() as conn:
                # è®€å–æ—¥æœŸ
                cur = conn.cursor()
                if days:
                    sql = f"SELECT DISTINCT date FROM stock_data ORDER BY date DESC LIMIT {days}"
                else:
                    sql = "SELECT DISTINCT date FROM stock_data ORDER BY date DESC"
                
                cur.execute(sql)
                dates = [row[0] for row in cur.fetchall()]
                
                if not dates:
                    print_flush("âš  æœ¬åœ°ç„¡æ•¸æ“šå¯ä¸Šå‚³")
                    return False
                
                total_dates = len(dates)
                for idx, date in enumerate(dates):
                    print_flush(f"æ­£åœ¨è™•ç†æ—¥æœŸ: {date} ({idx+1}/{total_dates})")
                    
                    # è®€å–è©²æ—¥æœŸçš„æ‰€æœ‰æ•¸æ“š
                    df = pd.read_sql_query(f"SELECT * FROM stock_data WHERE date='{date}'", conn)
                    
                    # æ•¸æ“šæ¸…æ´—: è™•ç† bytes é¡å‹çš„æ•¸æ“š
                    def clean_value(x):
                        if isinstance(x, bytes):
                            try:
                                return int.from_bytes(x, byteorder='little')
                            except:
                                return str(x)
                        return x

                    # æ‡‰ç”¨æ¸…æ´—å‡½æ•¸åˆ°æ‰€æœ‰æ¬„ä½
                    for col in df.columns:
                        if df[col].dtype == 'object':
                            df[col] = df[col].apply(clean_value)
                            
                    # å¼·åˆ¶è½‰æ› volume ç›¸é—œæ¬„ä½ç‚ºæ•´æ•¸
                    vol_cols = ['volume', 'vol_prev', 'volume_prev']
                    for col in vol_cols:
                        if col in df.columns:
                            df[col] = pd.to_numeric(df[col], errors='coerce')
                            df[col] = df[col].astype('Int64')
                            df[col] = df[col].apply(lambda x: int(x) if pd.notnull(x) else None)

                    # è½‰æ›ç‚º JSON æ ¼å¼ (records)
                    records = df.to_dict(orient='records')
                    
                    # åˆ†æ‰¹ä¸Šå‚³
                    batch_size = 500
                    total_recs = len(records)
                    for i in range(0, total_recs, batch_size):
                        batch = records[i:i+batch_size]
                        url = f"{SUPABASE_URL}/rest/v1/stock_data"
                        response = requests.post(url, headers=CloudSync.get_headers(), json=batch, verify=False)
                        if response.status_code not in [200, 201]:
                            print_flush(f"âš  ä¸Šå‚³å¤±æ•— ({date} æ‰¹æ¬¡ {i}): {response.text}")
                    
            print_flush("\nâœ“ æ•¸æ“šä¸Šå‚³å®Œæˆ")
            return True
        except Exception as e:
            print_flush(f"\nâŒ ä¸Šå‚³éŒ¯èª¤: {e}")
            return False

def calculate_stock_history_indicators(code, display_days=30):
    """è¨ˆç®—è‚¡ç¥¨æ­·å²æŠ€è¡“æŒ‡æ¨™ - å¼·åˆ¶é‡æ–°è¨ˆç®—ç‰ˆ (å®Œå…¨æ¢å¾©)"""
    try:
        # å¾ DB è®€å–åŸå§‹æ•¸æ“šï¼ˆä¸å¸¶ä»»ä½•å¿«å–æ¬„ä½ï¼‰
        with db_manager.get_connection() as conn:
            query = """
                SELECT date, open, high, low, close, volume 
                FROM stock_data 
                WHERE code=? 
                ORDER BY date ASC
            """
            df = pd.read_sql_query(query, conn, params=(code,))
        
        if df.empty or len(df) < 20:
            # print_flush(f"âš  {code} è³‡æ–™ä¸è¶³: åƒ…æœ‰{len(df)}ç­†,éœ€è‡³å°‘20ç­†")
            return None
        
        # ç¢ºä¿æ—¥æœŸæ ¼å¼æ­£ç¢º
        df['date'] = pd.to_datetime(df['date'])
        df = df.sort_values('date').reset_index(drop=True)
        
        # === å‘é‡åŒ–æŒ‡æ¨™è¨ˆç®—ï¼ˆå¼·åˆ¶é‡æ–°è¨ˆç®—ï¼‰===
        # MA
        df['MA3'] = df['close'].rolling(3).mean().round(2)
        df['MA20'] = df['close'].rolling(20).mean().round(2)
        df['MA60'] = df['close'].rolling(60).mean().round(2)
        df['MA120'] = df['close'].rolling(120).mean().round(2)
        df['MA200'] = df['close'].rolling(200).mean().round(2)
        
        # WMA (ä½¿ç”¨ calculate_wma å–å¾—åºåˆ—)
        df['WMA3'] = pd.Series(IndicatorCalculator.calculate_wma(df['close'].values, 3), index=df.index).round(2)
        df['WMA20'] = pd.Series(IndicatorCalculator.calculate_wma(df['close'].values, 20), index=df.index).round(2)
        df['WMA60'] = pd.Series(IndicatorCalculator.calculate_wma(df['close'].values, 60), index=df.index).round(2)
        df['WMA120'] = pd.Series(IndicatorCalculator.calculate_wma(df['close'].values, 120), index=df.index).round(2)
        df['WMA200'] = pd.Series(IndicatorCalculator.calculate_wma(df['close'].values, 200), index=df.index).round(2)
        
        # MFI
        df['MFI'] = IndicatorCalculator.calculate_mfi(df, 14).round(2)
        
        # VWAP
        df['VWAP'] = IndicatorCalculator.calculate_vwap_series(df, lookback=20).round(2)
        
        # CHG14
        df['CHG14'] = IndicatorCalculator.calculate_chg14_series(df).round(2)
        
        # RSI
        df['RSI'] = IndicatorCalculator.calculate_rsi_series(df, 14).round(2)
        
        # MACD
        macd, signal = IndicatorCalculator.calculate_macd_series(df)
        df['MACD'] = macd.round(2)
        df['SIGNAL'] = signal.round(2)
        
        # KD
        # kd = IndicatorCalculator.calculate_monthly_kd(df) 
        # KD
        # kd = IndicatorCalculator.calculate_monthly_kd(df) 
        # KD
        # kd = IndicatorCalculator.calculate_monthly_kd(df) 
        k_series, d_series = IndicatorCalculator.calculate_monthly_kd_series(df)
        
        # è¨ˆç®—æ—¥KD
        daily_k, daily_d = IndicatorCalculator.calculate_daily_kd_series(df)
        
        # è¨ˆç®—å‘¨KD
        week_k, week_d = IndicatorCalculator.calculate_weekly_kd_series(df)
        
        # [æ–°å¢] Smart Score è¨ˆç®—
        smart_score, smi_sig, nvi_sig, vsa_sig, svi_sig = IndicatorCalculator.calculate_smart_score_series(df)
        df['Smart_Score'] = smart_score
        df['SMI_Signal'] = smi_sig
        df['NVI_Signal'] = nvi_sig
        df['VSA_Signal'] = vsa_sig
        df['SVI_Signal'] = svi_sig
        df['Month_K'] = k_series.round(2)
        df['Month_D'] = d_series.round(2)
        df['Daily_K'] = daily_k.round(2)
        df['Daily_D'] = daily_d.round(2)
        # week_k/d are numpy arrays
        df['Week_K'] = pd.Series(week_k, index=df.index).round(2)
        df['Week_D'] = pd.Series(week_d, index=df.index).round(2)
        
        # [æ–°å¢] æ˜¨æ—¥æ”¶ç›¤èˆ‡æˆäº¤é‡ (ç”¨æ–¼è¨ˆç®—æ¼²è·Œå¹…èˆ‡å¢é‡)
        df['close_prev'] = df['close'].shift(1)
        df['vol_prev'] = df['volume'].shift(1)
        
        # === æº–å‚™çµæœåˆ—è¡¨ ===
        indicators_list = []
        # å¦‚æœ display_days ç‚º None æˆ– 0ï¼Œå‰‡è™•ç†æ‰€æœ‰è³‡æ–™
        start_index = 0 if not display_days else max(0, len(df) - display_days)
        
        for i in range(start_index, len(df)):
            row = df.iloc[i]
            prev_row = df.iloc[i-1] if i > 0 else row
            
            indicators = {
                'date': row['date'].strftime('%Y-%m-%d'),
                'close': row['close'],
                'volume': row['volume'],
                'close_prev': row['close_prev'] if pd.notnull(row['close_prev']) else None,
                'vol_prev': row['vol_prev'] if pd.notnull(row['vol_prev']) else None,
                'MA3': row['MA3'],
                'MA20': row['MA20'],
                'MA60': row['MA60'],
                'MA120': row['MA120'],
                'MA200': row['MA200'],
                'WMA3': row['WMA3'],
                'WMA20': row['WMA20'],
                'WMA60': row['WMA60'],
                'WMA120': row['WMA120'],
                'WMA200': row['WMA200'],
                'MA3_prev': prev_row['MA3'],
                'MA20_prev': prev_row['MA20'],
                'MA60_prev': prev_row['MA60'],
                'MA120_prev': prev_row['MA120'],
                'MA200_prev': prev_row['MA200'],
                'WMA3_prev': prev_row['WMA3'],
                'WMA20_prev': prev_row['WMA20'],
                'WMA60_prev': prev_row['WMA60'],
                'WMA120_prev': prev_row['WMA120'],
                'WMA200_prev': prev_row['WMA200'],
                'MFI': row['MFI'],
                'MFI_prev': prev_row['MFI'],
                'VWAP': row['VWAP'],
                'VWAP_prev': prev_row['VWAP'],
                'CHG14': row['CHG14'],
                'CHG14_prev': prev_row['CHG14'],
                'RSI': row['RSI'],
                'MACD': row['MACD'],
                'SIGNAL': row['SIGNAL'],
                'Month_K': row['Month_K'],
                'Month_D': row['Month_D'],
                'Daily_K': row['Daily_K'] if pd.notnull(row['Daily_K']) else None,
                'Daily_D': row['Daily_D'] if pd.notnull(row['Daily_D']) else None,
                'Week_K': row['Week_K'] if pd.notnull(row['Week_K']) else None,
                'Week_D': row['Week_D'] if pd.notnull(row['Week_D']) else None,
                'Month_K_prev': prev_row['Month_K'],
                'Month_D_prev': prev_row['Month_D'],
                'Daily_K_prev': prev_row['Daily_K'],
                'Daily_D_prev': prev_row['Daily_D'],
                'Week_K_prev': prev_row['Week_K'],
                'Week_D_prev': prev_row['Week_D'],
                'Smart_Score': row['Smart_Score'],
                'SMI_Signal': row['SMI_Signal'],
                'NVI_Signal': row['NVI_Signal'],
                'VSA_Signal': row['VSA_Signal'],
                'SVI_Signal': row['SVI_Signal']
            }
            
            # VP éœ€è¦å–®ç¨è¨ˆç®— (å› ç‚ºæ˜¯å‹•æ…‹å€é–“)
            current_window = df.iloc[max(0, i-19):i+1]
            vp = IndicatorCalculator.calculate_vp_scheme3(current_window, lookback=20)
            indicators['POC'] = vp['POC']
            indicators['VP_upper'] = vp['VP_upper']
            indicators['VP_lower'] = vp['VP_lower']
            
            indicators_list.append(indicators)
        
        return indicators_list[::-1] # åè½‰å›ç”±æ–°åˆ°èˆŠ
        
    except Exception as e:
        logging.error(f"è¨ˆç®—æŒ‡æ¨™å¤±æ•— {code}: {e}", exc_info=True)
        return None

# ==============================
# æƒæé‚è¼¯å‡½æ•¸
# ==============================
def scan_vp(indicators_data, mode='lower', min_volume=100):
    results = []
    for code, ind in indicators_data.items():
        # æˆäº¤é‡éæ¿¾
        vol = safe_num(ind.get('volume', 0))
        if vol < min_volume: continue

        close = safe_num(ind.get('close'))
        vp_lower = safe_num(ind.get('vp_lower') or ind.get('VP_lower'))
        vp_upper = safe_num(ind.get('vp_upper') or ind.get('VP_upper'))
        
        if not close: continue
        
        if mode == 'lower':
            if not vp_lower: continue
            # æ¥è¿‘ä¸‹ç·£ (æ”¯æ’)
            if abs(close - vp_lower) / close < 0.02: # 2% å…§
                results.append((code, 0, ind))
        else:
            if not vp_upper: continue
            # æ¥è¿‘ä¸Šç·£ (å£“åŠ›)
            if abs(close - vp_upper) / close < 0.02:
                results.append((code, 0, ind))
    return results

def scan_mfi_mode(indicators_data, order='asc', min_volume=0):
    results = []
    for code, ind in indicators_data.items():
        if not ind: continue
        # latest = ind_list[0] # [ä¿®æ­£] è¼¸å…¥æ˜¯ dict ä¸æ˜¯ list
        vol = safe_num(ind.get('volume', 0))
        if vol < min_volume: continue
        
        # [ä¿®æ­£] ç›¸å®¹ DB key (mfi14) èˆ‡è¨ˆç®— key (MFI)
        mfi = safe_num(ind.get('mfi14') or ind.get('MFI'))
        mfi_prev = safe_num(ind.get('mfi14_prev') or ind.get('MFI_prev'))
        
        if mfi is None or mfi_prev is None: continue
        
        if order == 'asc': # å°åˆ°å¤§ (æµå…¥)
            if mfi > mfi_prev and mfi < 30: # ä½æª”å›å‡
                results.append((code, mfi, ind))
        else: # å¤§åˆ°å° (æµå‡º)
            if mfi < mfi_prev and mfi > 70: # é«˜æª”åè½‰
                results.append((code, mfi, ind))
    return sorted(results, key=lambda x: x[1], reverse=(order=='desc'))

def scan_ma_mode(indicators_data, ma_type='MA200', min_volume=0):
    results = []
    for code, ind in indicators_data.items():
        if not ind: continue
        # latest = ind_list[0] # [ä¿®æ­£] è¼¸å…¥æ˜¯ dict ä¸æ˜¯ list
        vol = safe_num(ind.get('volume', 0))
        if vol < min_volume: continue
        
        close = safe_num(ind.get('close'))
        # [ä¿®æ­£] ç›¸å®¹ DB key (ma200) èˆ‡è¨ˆç®— key (MA200)
        ma_key = ma_type.lower()
        ma_val = safe_num(ind.get(ma_key) or ind.get(ma_type))
        
        if not (close and ma_val): continue
        
        diff_pct = (close - ma_val) / ma_val * 100
        if -10 <= diff_pct <= 0:
            results.append((code, diff_pct, ind))
            
    return sorted(results, key=lambda x: x[1])


def scan_smart_money_strategy():
    """è°æ˜éŒ¢æŒ‡æ¨™æƒæ (Smart Score >= 3) - è©³ç´°ç‰ˆ"""
    limit, min_vol = get_user_scan_params()
    
    print_flush(f"\næ­£åœ¨æƒæ è°æ˜éŒ¢æŒ‡æ¨™ (Smart Score >= 3)...")
    
    results = []
    stats = {
        'total': 0,
        'vol_pass': 0,
        'has_score': 0,
        'smi_sig': 0,
        'svi_sig': 0,
        'nvi_sig': 0,
        'vsa_sig': 0,
        'vwap_sig': 0,
        'score_3': 0,
        'score_4': 0,
        'score_5': 0
    }
    
    data = GLOBAL_INDICATOR_CACHE["data"]
    if not data:
        print_flush("âŒ ç„¡æŒ‡æ¨™æ•¸æ“šï¼Œè«‹å…ˆåŸ·è¡Œè³‡æ–™æ›´æ–°")
        return

    stats['total'] = len(data)
    
    for code, ind in data.items():
        try:
            # æˆäº¤é‡éæ¿¾
            vol = safe_float_preserving_none(ind.get('volume', 0))
            if vol is None or vol < min_vol:
                continue
            
            stats['vol_pass'] += 1
            
            # å–å¾— Smart Score (å„ªå…ˆä½¿ç”¨å°å¯«éµ)
            score = safe_int(ind.get('smart_score') or ind.get('Smart_Score'))
            
            if score is None:
                continue
                
            stats['has_score'] += 1
            
            # çµ±è¨ˆå„é …è¨Šè™Ÿ
            if safe_int(ind.get('smi_signal') or ind.get('SMI_Signal')) == 1:
                stats['smi_sig'] += 1
            if safe_int(ind.get('svi_signal') or ind.get('SVI_Signal')) == 1:
                stats['svi_sig'] += 1
            if safe_int(ind.get('nvi_signal') or ind.get('NVI_Signal')) == 1:
                stats['nvi_sig'] += 1
            if safe_int(ind.get('vsa_signal') or ind.get('VSA_Signal')) > 0:
                stats['vsa_sig'] += 1
            # VWAP Signal éœ€å¾ score åæ¨æˆ–ç›´æ¥æª¢æŸ¥ close > vwap
            if ind.get('close') and ind.get('VWAP'):
                if safe_float_preserving_none(ind.get('close')) > safe_float_preserving_none(ind.get('VWAP')):
                    stats['vwap_sig'] += 1
            
            # çµ±è¨ˆ Score åˆ†å¸ƒ
            if score >= 5:
                stats['score_5'] += 1
            if score >= 4:
                stats['score_4'] += 1
            if score >= 3:
                stats['score_3'] += 1
            
            # Filter: Smart Score >= 3
            if score >= 3:
                results.append((code, score, ind))
                
        except: continue
        
    # Sort by Score desc
    results.sort(key=lambda x: x[1], reverse=True)
    
    # é¡¯ç¤ºè©³ç´°ç¯©é¸éç¨‹
    print_flush("\n" + "=" * 60)
    print_flush("[ç¯©é¸éç¨‹] è°æ˜éŒ¢æŒ‡æ¨™å¤šå±¤ç¯©é¸")
    print_flush("=" * 60)
    print_flush(f"ç¸½è‚¡æ•¸: {stats['total']}")
    print_flush("â”€" * 60)
    print_flush(f"âœ“ æˆäº¤é‡ >= {min_vol//1000}å¼µ            â†’ {stats['vol_pass']} æª”")
    print_flush(f"âœ“ æœ‰ Smart Score æ•¸æ“š       â†’ {stats['has_score']} æª”")
    print_flush("â”€" * 60)
    print_flush("ã€å„é …è¨Šè™Ÿçµ±è¨ˆã€‘(é€šéæˆäº¤é‡é–€æª»è€…)")
    print_flush(f"  â€¢ SMI è¨Šè™Ÿ (å‹•èƒ½ä¸Šå‡)     â†’ {stats['smi_sig']} æª”")
    print_flush(f"  â€¢ SVI è¨Šè™Ÿ (ç›¸å°çˆ†é‡)     â†’ {stats['svi_sig']} æª”")
    print_flush(f"  â€¢ NVI è¨Šè™Ÿ (æ•£æˆ¶é›¢å ´)     â†’ {stats['nvi_sig']} æª”")
    print_flush(f"  â€¢ VSA è¨Šè™Ÿ (åœæ­¢é‡/æ¼²åœ)  â†’ {stats['vsa_sig']} æª”")
    print_flush(f"  â€¢ VWAPè¨Šè™Ÿ (åƒ¹>å‡åƒ¹)      â†’ {stats['vwap_sig']} æª”")
    print_flush("â”€" * 60)
    print_flush("ã€Smart Score åˆ†å¸ƒã€‘(æ»¿åˆ†5åˆ†)")
    print_flush(f"  â€¢ Score >= 3 (è²·å…¥è¨Šè™Ÿ)   â†’ {stats['score_3']} æª”")
    print_flush(f"  â€¢ Score >= 4 (å¼·çƒˆè²·å…¥)   â†’ {stats['score_4']} æª”")
    print_flush(f"  â€¢ Score = 5  (æ¥µå¼·è¨Šè™Ÿ)   â†’ {stats['score_5']} æª”")
    print_flush("=" * 60)
    
    print_flush(f"\nã€è°æ˜éŒ¢æƒæçµæœã€‘æ‰¾åˆ° {len(results)} æª”ç¬¦åˆæ¢ä»¶çš„è‚¡ç¥¨ (é¡¯ç¤ºå‰{limit}æª”)")
    print_flush("=" * 80)
    
    for i, (code, score, ind) in enumerate(results[:limit]):
        name = get_correct_stock_name(code, ind.get('name', code))
        print_flush(f"{i+1}. {format_smart_money_result(code, name, ind)}")
    
    print_flush("=" * 80)
    print_flush(f"[é¡¯ç¤ºæª”æ•¸: {min(limit, len(results))}/{len(results)}]")
    print_flush("=" * 80)

def format_smart_money_result(code, name, ind):
    """æ ¼å¼åŒ–è°æ˜éŒ¢æƒæçµæœ"""
    close = safe_float_preserving_none(ind.get('close'))
    score = safe_int(ind.get('smart_score') or ind.get('Smart_Score'))
    smi = safe_float_preserving_none(ind.get('smi') or ind.get('SMI'))
    svi = safe_float_preserving_none(ind.get('svi') or ind.get('SVI'))
    
    result = f"{code:6s} {name:10s} | Score: {score}/5"
    if close:
        result += f" | æ”¶: {close:6.2f}"
    if smi:
        result += f" | SMI: {smi:6.1f}"
    
    return result

def scan_triple_filter_mode_v32(all_indicators, min_volume=500000, limit=20):
    """ä¸‰é‡ç¯©é¸é€²éšç‰ˆ"""
    results = []
    total = len(all_indicators)
    
    stats = {
        "total": total, "volume_pass": 0, "trend_pass": 0, 
        "mfi_pass": 0, "breakout_pass": 0, "final_pass": 0
    }
    
    with ProgressTracker(3) as progress:
        for idx, (code, indicators) in enumerate(all_indicators.items()):
            if not indicators: continue
            # indicators = ind_list[0] # [ä¿®æ­£] è¼¸å…¥æ˜¯ dict ä¸æ˜¯ list
            
            # 1. æˆäº¤é‡æª¢æŸ¥
            vol = safe_num(indicators.get('volume', 0))
            vol_prev = safe_num(indicators.get('vol_prev', 0))
            if vol < min_volume: continue
            if vol_prev and vol <= vol_prev: continue
            stats["volume_pass"] += 1
            
            # 2. è¶¨å‹¢æª¢æŸ¥
            if not is_wma20_rising(indicators.get('wma20') or indicators.get('WMA20'), 
                                 indicators.get('wma20_prev') or indicators.get('WMA20_prev')): continue
            if not is_vwap20_rising(indicators.get('vwap20') or indicators.get('VWAP'), 
                                  indicators.get('vwap20_prev') or indicators.get('VWAP_prev')): continue
            stats["trend_pass"] += 1
            
            # 3. MFI å‹•èƒ½æª¢æŸ¥
            if not is_mfi14_rising(indicators.get('mfi14') or indicators.get('MFI'), 
                                 indicators.get('mfi14_prev') or indicators.get('MFI_prev')): continue
            stats["mfi_pass"] += 1
            
            # 4. çªç ´æª¢æŸ¥
            close = safe_num(indicators.get('close'))
            vwap = safe_num(indicators.get('vwap20') or indicators.get('VWAP'))
            poc = safe_num(indicators.get('vp_poc') or indicators.get('POC'))
            is_breakout = (close and vwap and close > vwap) or (close and poc and close > poc)
            if not is_breakout: continue
            stats["breakout_pass"] += 1
            
            stats["final_pass"] += 1
            results.append((code, indicators.get('mfi14') or indicators.get('MFI', 0), indicators))
            
            if idx % 50 == 0:
                progress.update_lines(
                    f"æƒæé€²åº¦: {idx+1}/{total}",
                    f"é€šé: é‡{stats['volume_pass']} è¶¨å‹¢{stats['trend_pass']} MFI{stats['mfi_pass']} çªç ´{stats['breakout_pass']}",
                    f"Checking: {code}"
                )
            
    print_flush(f"\n[Debug] ç¯©é¸çµ±è¨ˆ: ç¸½æ•¸{stats['total']} -> é‡{stats['volume_pass']} -> è¶¨å‹¢{stats['trend_pass']} -> MFI{stats['mfi_pass']} -> çªç ´{stats['breakout_pass']}")
    
    print_flush(f"âœ“ æˆäº¤é‡ >= {int(min_volume/1000)}å¼µ ä¸” å¢é‡(ä»Š>æ˜¨) â†’ {stats['volume_pass']}æª”")
    print_flush(f"âœ“ WMA20 & VWAP é›™ä¸Šæš             â†’ {stats['trend_pass']}æª”")
    print_flush(f"âœ“ MFI14 ä¸Šæš (è³‡é‡‘æµå…¥)             â†’ {stats['mfi_pass']}æª”")
    print_flush(f"âœ“ åƒ¹æ ¼çªç ´ (Close > VWAP or POC)    â†’ {stats['breakout_pass']}æª”")
    
    print_flush(f"\nã€ä¸‰é‡ç¯©é¸çµæœã€‘æ‰¾åˆ° {len(results)} æª”ç²¾é¸è‚¡ç¥¨")
    print_flush("=" * 80)
    for i, (code, mfi, ind) in enumerate(results[:limit]):
        name = ind.get('name', code)
        print_flush(f"{i+1}. {format_scan_result(code, name, ind)}")
    print_flush("=" * 80)
    return results

def execute_kd_golden_scan():
    """æœˆKDäº¤å‰æƒæ (Kâ†‘ç©¿è¶ŠDâ†‘ æˆ– Dâ†‘ç©¿è¶ŠKâ†‘)"""
    # 1. ç²å–åƒæ•¸
    limit, min_vol = get_user_scan_params()
    
    print_flush(f"\næ­£åœ¨æƒæ æœˆKDäº¤å‰ (Kâ†‘ç©¿è¶ŠDâ†‘ æˆ– Dâ†‘ç©¿è¶ŠKâ†‘)...")
    
    results = []
    data = GLOBAL_INDICATOR_CACHE["data"]
    if not data:
        print_flush("âŒ ç„¡æŒ‡æ¨™æ•¸æ“šï¼Œè«‹å…ˆåŸ·è¡Œè³‡æ–™æ›´æ–°")
        return

    for code, ind in data.items():
        try:
            # æˆäº¤é‡éæ¿¾
            vol = safe_float_preserving_none(ind.get('volume', 0))
            if vol is None or vol < min_vol:
                continue

            k = safe_float_preserving_none(ind.get('month_k'))
            d = safe_float_preserving_none(ind.get('month_d'))
            k_prev = safe_float_preserving_none(ind.get('month_k_prev'))
            d_prev = safe_float_preserving_none(ind.get('month_d_prev'))
            
            if None in [k, d, k_prev, d_prev]:
                continue
            
            # åˆ¤æ–·è¶¨å‹¢ (æ˜¯å¦å‘ä¸Š)
            k_rising = k > k_prev
            d_rising = d > d_prev
            
            # 1. Kâ†‘ç©¿è¶ŠDâ†‘ (é»ƒé‡‘äº¤å‰ä¸”é›™ç·šå‘ä¸Š)
            if (k > d and k_prev <= d_prev) and k_rising and d_rising:
                results.append((code, k, ind, "Kâ†‘ç©¿è¶ŠDâ†‘"))
                
            # 2. Dâ†‘ç©¿è¶ŠKâ†‘ (D å‘ä¸Šç©¿è¶Š Kï¼Œä¸”é›™ç·šå‘ä¸Š)
            elif (d > k and d_prev <= k_prev) and d_rising and k_rising:
                results.append((code, k, ind, "Dâ†‘ç©¿è¶ŠKâ†‘"))
                
        except: continue
        
    # æŒ‰ K å€¼ç”±å°åˆ°å¤§æ’åº (0% -> 100%)
    results.sort(key=lambda x: x[1]) 
    
    print_flush(f"\næœˆKDäº¤å‰: æ‰¾åˆ° {len(results)} æª”ç¬¦åˆæ¢ä»¶çš„è‚¡ç¥¨ (é¡¯ç¤ºå‰{limit}æª”)")
    print_flush(f"æ’åºæ–¹å¼: Kå€¼ç”±å°åˆ°å¤§ (0% -> 100%)")
    print_flush("=" * 80)
    
    for i, (code, k, ind, type_str) in enumerate(results[:limit]):
        name = get_correct_stock_name(code, ind.get('name', code))
        # é¡¯ç¤ºé¡å¤–è³‡è¨Š
        extra_info = f"{type_str} MK:{k:.1f} MD:{ind.get('month_d'):.1f}"
        print_flush(f"{i+1}. {format_scan_result(code, name, ind)} [{extra_info}]")
    
    print_flush("=" * 80)
    print_flush(f"[é¡¯ç¤ºæª”æ•¸: {min(limit, len(results))}/{len(results)}]")

def scan_ma_alignment_rising(check_price_above=True):
    """å‡ç·šå¤šé ­æƒæ (äº”ç·šä¸Šæš + è‚¡åƒ¹åœ¨å‡ç·šä¹‹ä¸Š + 0-10%é™åˆ¶)
    
    æ¢ä»¶:
    1. äº”æ¢å‡ç·šå‡åœ¨ä¸Šæš (ä»Šæ—¥ > æ˜¨æ—¥)
    2. è‚¡åƒ¹åœ¨æ‰€æœ‰å‡ç·šä¹‹ä¸Š
    3. è‚¡åƒ¹è·é›¢æœ€é«˜å‡ç·šåœ¨ 0-10% ä»¥å…§
    """
    # 1. ç²å–åƒæ•¸
    limit, min_vol = get_user_scan_params()

    title = "å‡ç·šå¤šé ­ (äº”ç·šä¸Šæš+è‚¡åƒ¹åœ¨ä¸Š+0-10%)" if check_price_above else "å‡ç·šå¤šé ­ (äº”ç·šä¸Šæš)"
    print_flush(f"\næ­£åœ¨æƒæ {title}...")
    
    results = []
    data = GLOBAL_INDICATOR_CACHE["data"]
    if not data:
        print_flush("âŒ ç„¡æŒ‡æ¨™æ•¸æ“šï¼Œè«‹å…ˆåŸ·è¡Œè³‡æ–™æ›´æ–°")
        return

    for code, ind in data.items():
        try:
            # æˆäº¤é‡éæ¿¾
            vol = safe_float_preserving_none(ind.get('volume', 0))
            if vol is None or vol < min_vol:
                continue

            close = safe_float_preserving_none(ind.get('close'))
            ma3 = safe_float_preserving_none(ind.get('ma3'))
            ma20 = safe_float_preserving_none(ind.get('ma20'))
            ma60 = safe_float_preserving_none(ind.get('ma60'))
            ma120 = safe_float_preserving_none(ind.get('ma120'))
            ma200 = safe_float_preserving_none(ind.get('ma200'))
            
            # å–å¾—å‰ä¸€æ—¥å‡ç·šå€¼ (ç”¨æ–¼åˆ¤æ–·ä¸Šæš)
            ma3_prev = safe_float_preserving_none(ind.get('ma3_prev'))
            ma20_prev = safe_float_preserving_none(ind.get('ma20_prev'))
            ma60_prev = safe_float_preserving_none(ind.get('ma60_prev'))
            ma120_prev = safe_float_preserving_none(ind.get('ma120_prev'))
            ma200_prev = safe_float_preserving_none(ind.get('ma200_prev'))
            
            if None in [close, ma3, ma20, ma60, ma120, ma200]:
                continue
            
            # æ¢ä»¶1: äº”æ¢å‡ç·šå‡åœ¨ä¸Šæš (å¿…é ˆæœ‰å‰ä¸€æ—¥è³‡æ–™)
            if not (ma3_prev and ma20_prev and ma60_prev and ma120_prev and ma200_prev):
                continue
                
            is_all_rising = (ma3 > ma3_prev and 
                            ma20 > ma20_prev and
                            ma60 > ma60_prev and
                            ma120 > ma120_prev and
                            ma200 > ma200_prev)
            if not is_all_rising:
                continue
            
            # æ¢ä»¶2: è‚¡åƒ¹åœ¨æ‰€æœ‰å‡ç·šä¹‹ä¸Š
            if check_price_above:
                is_above = (close > ma3 and close > ma20 and close > ma60 and 
                           close > ma120 and close > ma200)
                if not is_above:
                    continue
            
            # æ¢ä»¶3: è‚¡åƒ¹è·é›¢æœ€é«˜å‡ç·šåœ¨ 0-10% ä»¥å…§
            highest_ma = max(ma3, ma20, ma60, ma120, ma200)
            if highest_ma <= 0:
                continue
                
            distance_pct = (close - highest_ma) / highest_ma * 100
            if not (0 <= distance_pct <= 10):
                continue
            
            # é€šéæ‰€æœ‰æ¢ä»¶ï¼ŒåŠ å…¥çµæœ
            results.append((code, distance_pct, ind))
                
        except: continue
    
    # ä¾ç…§è·é›¢æœ€é«˜å‡ç·šçš„ç™¾åˆ†æ¯”æ’åºï¼ˆç”±è¿‘åˆ°é : 0% â†’ 10%ï¼‰
    results = sorted(results, key=lambda x: x[1])
        
    print_flush(f"\n{title}: æ‰¾åˆ° {len(results)} æª”ç¬¦åˆæ¢ä»¶çš„è‚¡ç¥¨ (é¡¯ç¤ºå‰{limit}æª”)")
    print_flush("=" * 80)
    print_flush(f"{'æ’åº':>4s} {'è‚¡è™Ÿ':6s} {'åç¨±':10s} | {'æ”¶ç›¤åƒ¹':>8s} | {'è·æœ€é«˜MA':>8s} | {'æˆäº¤é‡':>10s}")
    print_flush("-" * 80)
    
    for i, (code, dist_pct, ind) in enumerate(results[:limit]):
        name = get_correct_stock_name(code, ind.get('name', code))
        close = safe_float_preserving_none(ind.get('close'))
        vol = safe_float_preserving_none(ind.get('volume'))
        vol_display = vol / 1000 if vol else 0  # è½‰æ›ç‚ºå¼µ
        
        print_flush(
            f"{i+1:4d}. {code:6s} {name:10s} | "
            f"{close:8.2f} | "
            f"{dist_pct:7.2f}% | "
            f"{vol_display:9.0f}å¼µ"
        )
    
    print_flush("=" * 80)
    print_flush(f"[é¡¯ç¤ºæª”æ•¸: {min(limit, len(results))}/{len(results)}]")
    print_flush("=" * 80)

def triple_filter_scan():
    """ä¸‰é‡ç¯©é¸å…¥å£"""
    # 1. ç²å–åƒæ•¸
    limit, min_vol = get_user_scan_params()

    title = "ä¸‰é‡ç¯©é¸ (é€²éšç‰ˆ)"
    print_flush(f"â—‡ æ­£åœ¨åŸ·è¡Œ{title}... (æœ€å°æˆäº¤é‡: {min_vol}å¼µ, ä½¿ç”¨ {len(GLOBAL_INDICATOR_CACHE['data'])} æª”æŒ‡æ¨™)")
    
    results = scan_triple_filter_mode_v32(GLOBAL_INDICATOR_CACHE["data"], min_volume=min_vol, limit=limit)

# ==============================
# è¼”åŠ©åˆ¤æ–·å‡½æ•¸
# ==============================
def is_wma20_rising(curr, prev):
    return curr is not None and prev is not None and curr > prev

def is_vwap20_rising(curr, prev):
    return curr is not None and prev is not None and curr > prev

def is_mfi14_rising(curr, prev):
    return curr is not None and prev is not None and curr > prev

def get_display_limit():
    return 20

def get_volume_limit():
    return 1000

def get_user_scan_params():
    """ç²å–ä½¿ç”¨è€…è¼¸å…¥çš„æƒæåƒæ•¸ (æª”æ•¸èˆ‡æˆäº¤é‡)"""
    try:
        print("é¸æ“‡æª”æ•¸(é è¨­30æª”): ", end='', flush=True)
        l = sys.stdin.readline().strip()
        limit = int(l) if l else 30
    except: limit = 30
    
    try:
        print("å¤§æ–¼æˆäº¤é‡(é è¨­å¤§æ–¼100å¼µ): ", end='', flush=True)
        v = sys.stdin.readline().strip()
        min_vol_lots = int(v) if v else 100
        min_vol = min_vol_lots * 1000 # è½‰æ›ç‚ºè‚¡æ•¸
    except: min_vol = 100 * 1000
    
    return limit, min_vol

# ==============================
# å¸‚å ´æƒæåŠŸèƒ½ (é‚„åŸ)
# ==============================
def scan_mfi_divergence():
    print_flush("\n[æƒæ] MFI èƒŒé›¢åµæ¸¬ (é«˜æª”èƒŒé›¢/ä½æª”èƒŒé›¢)...")
    try:
        with db_manager.get_connection() as conn:
            # è®€å–æœ€è¿‘è³‡æ–™
            df = pd.read_sql("SELECT * FROM stock_data WHERE date >= date('now', '-60 days')", conn)
        
        if df.empty:
            print_flush("âŒ ç„¡è³‡æ–™å¯æƒæ")
            return

        results = []
        codes = df['code'].unique()
        
        for code in codes:
            sub = df[df['code'] == code].sort_values('date')
            if len(sub) < 20: continue
            
            curr_close = sub.iloc[-1]['close']
            curr_mfi = sub.iloc[-1]['mfi14']
            
            # ç°¡å–®èƒŒé›¢é‚è¼¯: åƒ¹æ ¼å‰µæ–°é«˜ä½† MFI æœªå‰µæ–°é«˜ (é«˜æª”èƒŒé›¢)
            # æˆ– åƒ¹æ ¼å‰µæ–°ä½ä½† MFI æœªå‰µæ–°ä½ (ä½æª”èƒŒé›¢)
            # é€™è£¡å¯¦ä½œä¸€å€‹ç°¡åŒ–ç‰ˆæœ¬
            if curr_mfi > 80:
                results.append((code, sub.iloc[-1]['name'], "MFIè¶…è²·", curr_mfi))
            elif curr_mfi < 20:
                results.append((code, sub.iloc[-1]['name'], "MFIè¶…è³£", curr_mfi))
                
        print_flush(f"æƒæå®Œæˆï¼Œç™¼ç¾ {len(results)} æª”æ½›åœ¨è¨Šè™Ÿ")
        for res in results[:10]:
            print_flush(f"  {res[0]} {res[1]}: {res[2]} ({res[3]:.1f})")
            
    except Exception as e:
        print_flush(f"âŒ æƒæå¤±æ•—: {e}")

def scan_volume_anomaly():
    print_flush("\n[æƒæ] æˆäº¤é‡ç•°å¸¸ (çˆ†é‡/ç¸®é‡)...")
    try:
        with db_manager.get_connection() as conn:
            # å–å¾—æœ€æ–°å…©å¤©è³‡æ–™
            dates = pd.read_sql("SELECT DISTINCT date FROM stock_data ORDER BY date DESC LIMIT 2", conn)['date'].tolist()
            if len(dates) < 2:
                print_flush("âŒ è³‡æ–™ä¸è¶³")
                return
                
            curr_date = dates[0]
            prev_date = dates[1]
            
            query = f"""
                SELECT T1.code, T1.name, T1.volume as vol_curr, T2.volume as vol_prev
                FROM stock_data T1
                JOIN stock_data T2 ON T1.code = T2.code
                WHERE T1.date = '{curr_date}' AND T2.date = '{prev_date}'
            """
            df = pd.read_sql(query, conn)
            
        anomalies = []
        for _, row in df.iterrows():
            if row['vol_prev'] > 0:
                ratio = row['vol_curr'] / row['vol_prev']
                if ratio > 3.0 and row['vol_curr'] > 1000000: # 3å€çˆ†é‡ä¸”å¤§æ–¼1000å¼µ
                    anomalies.append((row['code'], row['name'], "çˆ†é‡", ratio))
                elif ratio < 0.3 and row['vol_prev'] > 1000000: # 0.3å€ç¸®é‡
                    anomalies.append((row['code'], row['name'], "æ€¥ç¸®", ratio))
                    
        print_flush(f"æƒæå®Œæˆï¼Œç™¼ç¾ {len(anomalies)} æª”ç•°å¸¸")
        for res in sorted(anomalies, key=lambda x: x[3], reverse=True)[:10]:
            print_flush(f"  {res[0]} {res[1]}: {res[2]} {res[3]:.1f}å€")
            
    except Exception as e:
        print_flush(f"âŒ æƒæå¤±æ•—: {e}")

def scan_price_anomaly():
    print_flush("\n[æƒæ] åƒ¹æ ¼ç•°å¸¸ (æ€¥æ¼²/æ€¥è·Œ)...")
    try:
        with db_manager.get_connection() as conn:
            # å–å¾—æœ€æ–°è³‡æ–™
            df = pd.read_sql("SELECT * FROM stock_data WHERE date = (SELECT MAX(date) FROM stock_data)", conn)
            
        if df.empty: return
        
        # è¨ˆç®—æ¼²è·Œå¹…
        df['pct_chg'] = (df['close'] - df['close_prev']) / df['close_prev'] * 100
        
        up = df[df['pct_chg'] > 9.0]
        down = df[df['pct_chg'] < -9.0]
        
        print_flush(f"æ¼²åœ/æ€¥æ¼² (>9%): {len(up)} æª”")
        for _, row in up.head(5).iterrows():
            print_flush(f"  {row['code']} {row['name']}: +{row['pct_chg']:.2f}%")
            
        print_flush(f"è·Œåœ/æ€¥è·Œ (<-9%): {len(down)} æª”")
        for _, row in down.head(5).iterrows():
            print_flush(f"  {row['code']} {row['name']}: {row['pct_chg']:.2f}%")
            
    except Exception as e:
        print_flush(f"âŒ æƒæå¤±æ•—: {e}")

def scan_comprehensive():
    print_flush("\n[æƒæ] ç¶œåˆæƒæ (MFI + æˆäº¤é‡ + åƒ¹æ ¼)...")
    scan_mfi_divergence()
    scan_volume_anomaly()
    scan_price_anomaly()

# ==============================
# é¸å–®ç³»çµ±
# ==============================
def market_scan_menu():
    """å¸‚å ´æƒæä¸»é¸å–®"""
    while True:
        print_flush("\n" + "="*80)
        print_flush("ã€å¸‚å ´æƒæã€‘")
        print_flush("="*80)
        print_flush("[1] VPæƒæ")
        print_flush("[2] MFIæƒæ")
        print_flush("[3] å‡ç·šæƒæ")
        print_flush("[4] ä¸‰é‡ç¯©é¸ (é€²éšç‰ˆ)")
        print_flush("[5] æœˆKDäº¤å‰ (Kâ†‘ç©¿è¶ŠDâ†‘ æˆ– Dâ†‘ç©¿è¶ŠKâ†‘)")
        print_flush("[6] å‡ç·šå¤šé ­ (äº”ç·šä¸Šæš+è‚¡åƒ¹åœ¨ä¸Š+0-10%)")
        print_flush("[7] è°æ˜éŒ¢æƒæ (Smart Score >= 3)")
        print_flush("[8] é‡æ–°è¼‰å…¥æŒ‡æ¨™")
        print_flush("[0] è¿”å›ä¸»é¸å–®")
        
        ch = read_single_key()
        
        # æª¢æŸ¥å¿«å–
        if ch in ['1', '2', '3', '4', '5', '6', '7'] and not GLOBAL_INDICATOR_CACHE["data"]:
            print_flush("\næ­£åœ¨è¼‰å…¥æŒ‡æ¨™...")
            GLOBAL_INDICATOR_CACHE["data"] = step4_load_data()
        
        if ch == '1':
            vp_scan_submenu()
        elif ch == '2':
            mfi_scan_submenu()
        elif ch == '3':
            ma_scan_submenu()
        elif ch == '4':
            triple_filter_scan()
        elif ch == '5':
            execute_kd_golden_scan()
        elif ch == '6':
            scan_ma_alignment_rising(check_price_above=True)
        elif ch == '7':
            scan_smart_money_strategy()
        elif ch == '8':
            print_flush("\næ­£åœ¨é‡æ–°è¼‰å…¥æŒ‡æ¨™...")
            GLOBAL_INDICATOR_CACHE["data"] = step4_load_data()
        elif ch == '0':
            break

def vp_scan_submenu():
    """VPæƒæå­é¸å–®"""
    print_flush("\nã€VPæƒæã€‘")
    print_flush(f"[å·²è¼‰å…¥æŒ‡æ¨™: {len(GLOBAL_INDICATOR_CACHE['data'])} æª”]")
    print_flush("[1] VP æ¥è¿‘ä¸‹ç·£ (æ”¯æ’)")
    print_flush("[2] VP æ¥è¿‘ä¸Šç·£ (å£“åŠ›)")
    print_flush("[0] è¿”å›")
    
    ch = read_single_key()
    if ch == '0': return
    
    mode = 'lower' if ch == '1' else 'upper'
    title = "VP æ¥è¿‘ä¸‹ç·£ (æ”¯æ’)" if mode == 'lower' else "VP æ¥è¿‘ä¸Šç·£ (å£“åŠ›)"
    
    if ch in ['1', '2']:
        # 1. ç²å–åƒæ•¸
        limit, min_vol = get_user_scan_params()

        print_flush(f"\næ­£åœ¨æƒæ {title}...")
        res = scan_vp(GLOBAL_INDICATOR_CACHE["data"], mode, min_volume=min_vol)
        
        print_flush(f"\n{title}: æ‰¾åˆ° {len(res)} æª”ç¬¦åˆæ¢ä»¶çš„è‚¡ç¥¨ (é¡¯ç¤ºå‰{limit}æª”)")
        print_flush("=" * 80)
        for i, (code, pct, ind) in enumerate(res[:limit]):
            print_flush(f"{i+1}. {format_scan_result(code, ind['name'], ind)}")
        print_flush("=" * 80)
        print_flush(f"[é¡¯ç¤ºæª”æ•¸: {min(limit, len(res))}/{len(res)}]")

def mfi_scan_submenu():
    """MFIæƒæå­é¸å–®"""
    print_flush("\nã€MFIæƒæã€‘")
    print_flush(f"[å·²è¼‰å…¥æŒ‡æ¨™: {len(GLOBAL_INDICATOR_CACHE['data'])} æª”]")
    print_flush("[1] MFIç”±å°â†’å¤§ (è³‡é‡‘æµå…¥é–‹å§‹)")
    print_flush("[2] MFIç”±å¤§â†’å° (è³‡é‡‘æµå‡ºçµæŸ)")
    print_flush("[0] è¿”å›")
    
    ch = read_single_key()
    if ch == '0': return
    
    if ch in ['1', '2']:
        # 1. ç²å–åƒæ•¸
        limit, min_vol = get_user_scan_params()

        order = 'asc' if ch == '1' else 'desc'
        title = "MFIç”±å°â†’å¤§ (è³‡é‡‘æµå…¥é–‹å§‹)" if order == 'asc' else "MFIç”±å¤§â†’å° (è³‡é‡‘æµå‡ºçµæŸ)"
        
        print_flush(f"\næ­£åœ¨æƒæ {title}...")
        results = scan_mfi_mode(GLOBAL_INDICATOR_CACHE["data"], order=order, min_volume=min_vol)
        
        print_flush(f"\n{title}: æ‰¾åˆ° {len(results)} æª”ç¬¦åˆæ¢ä»¶çš„è‚¡ç¥¨ (é¡¯ç¤ºå‰{limit}æª”)")
        print_flush("=" * 80)
        
        for i, (code, mfi, indicators) in enumerate(results[:limit], 1):
            name = get_correct_stock_name(code, indicators.get('name', code))
            print_flush(f"\n{i}. {format_scan_result(code, name, indicators)}")
        
        print_flush("=" * 80)
        print_flush(f"[é¡¯ç¤ºæª”æ•¸: {min(limit, len(results))}/{len(results)}]")

def ma_scan_submenu():
    """å‡ç·šæƒæå­é¸å–®"""
    print_flush("\nã€å‡ç·šæƒæã€‘")
    print_flush(f"[å·²è¼‰å…¥æŒ‡æ¨™: {len(GLOBAL_INDICATOR_CACHE['data'])} æª”]")
    print_flush("[1] ä½æ–¼MA200 -0%~-10%")
    print_flush("[2] ä½æ–¼MA20 -0%~-10%")
    print_flush("[0] è¿”å›")
    
    ch = read_single_key()
    if ch == '0': return
    
    if ch in ['1', '2']:
        # 1. ç²å–åƒæ•¸
        limit, min_vol = get_user_scan_params()

        ma_type = 'MA200' if ch == '1' else 'MA20'
        title = f"ä½æ–¼{ma_type} -0%~-10%"
        
        print_flush(f"\næ­£åœ¨æƒæ {title}...")
        results = scan_ma_mode(GLOBAL_INDICATOR_CACHE["data"], ma_type=ma_type, min_volume=min_vol)
        
        print_flush(f"\n{title}: æ‰¾åˆ° {len(results)} æª”ç¬¦åˆæ¢ä»¶çš„è‚¡ç¥¨ (é¡¯ç¤ºå‰{limit}æª”)")
        print_flush("=" * 80)
        
        for i, (code, pct, indicators) in enumerate(results[:limit], 1):
            name = get_correct_stock_name(code, indicators.get('name', code))
            print_flush(f"\n{i}. {format_scan_result(code, name, indicators)}")
        
        print_flush("=" * 80)
        print_flush(f"[é¡¯ç¤ºæª”æ•¸: {min(limit, len(results))}/{len(results)}]")

def data_management_menu():
    """è³‡æ–™ç®¡ç†å­é¸å–®"""
    while True:
        print_flush("\n" + "="*60)
        print_flush("ã€è³‡æ–™ç®¡ç†èˆ‡æ›´æ–°ã€‘")
        print_flush("="*60)
        print_flush("[1] æ­¥é©Ÿ1: æ›´æ–°ä¸Šå¸‚æ«ƒæ¸…å–®")
        print_flush("[2] æ­¥é©Ÿ2: ä¸‹è¼‰ TPEx (ä¸Šæ«ƒ)")
        print_flush("[3] æ­¥é©Ÿ3: ä¸‹è¼‰ TWSE (ä¸Šå¸‚)")
        print_flush("[4] æ­¥é©Ÿ4: æª¢æŸ¥æ•¸æ“šç¼ºå¤±")
        print_flush("[5] æ­¥é©Ÿ5: æ¸…ç†ä¸‹å¸‚è‚¡ç¥¨")
        print_flush("[6] æ­¥é©Ÿ6: é©—è­‰ä¸€è‡´æ€§ä¸¦è£œæ¼ (æ–·é»çºŒæŠ“)")
        print_flush("[7] æ­¥é©Ÿ7: è¨ˆç®—æŠ€è¡“æŒ‡æ¨™")
        print_flush("-" * 60)
        print_flush("[8] ä¸€éµåŸ·è¡Œæ¯æ—¥æ›´æ–° (Steps 1->2->3->4->5->6->7)")
        print_flush("[9] å¿«é€Ÿæ›´æ–°ï¼ˆåƒ… 2->3->7ï¼Œè·³éè£œæ¼ï¼‰")
        print_flush("[0] è¿”å›ä¸»é¸å–®")

        ch = read_single_key()

        if ch == '1': step1_fetch_stock_list()
        elif ch == '2': step2_download_tpex_daily()
        elif ch == '3': step3_download_twse_daily()
        elif ch == '4': step4_check_data_gaps()
        elif ch == '5': step5_clean_delisted()
        elif ch == '6': step6_verify_and_backfill(resume=True)
        elif ch == '7': 
            step7_calc_indicators()
            GLOBAL_INDICATOR_CACHE["data"] = {}
            print_flush("âœ“ ç³»çµ±å¿«å–å·²æ¸…é™¤")
        elif ch == '8':
            step1_fetch_stock_list()  # å…ˆæ›´æ–°æ¸…å–®
            updated_codes = set()
            
            s2 = step2_download_tpex_daily()
            if isinstance(s2, set): updated_codes.update(s2)
            
            s3 = step3_download_twse_daily()
            if isinstance(s3, set): updated_codes.update(s3)
            
            step5_clean_delisted()  # æœ‰æ¸…å–®æ‰èƒ½æ­£ç¢ºæ¸…ç†
            step4_check_data_gaps() # æ–°å¢: æª¢æŸ¥æ•¸æ“šç¼ºå¤±
            data = step4_load_data()
            
            s6 = step6_verify_and_backfill(data, resume=True) # ä¿®æ­£: å•Ÿç”¨æ–·é»çºŒå‚³
            if isinstance(s6, set): updated_codes.update(s6)
            
            # [ä¿®æ­£] ä¸ä½¿ç”¨ target_codesï¼Œå¼·åˆ¶ Step 7 æƒææ‰€æœ‰è‚¡ç¥¨
            # Step 7 å…§å·²æœ‰åš´æ ¼çš„ SQL æª¢æŸ¥ï¼Œè‹¥æŒ‡æ¨™å·²å­˜åœ¨æœƒè‡ªå‹•è·³éï¼Œä¸æœƒæµªè²»æ™‚é–“
            # é€™æ¨£èƒ½ç¢ºä¿å³ä½¿ Step 6 æ²’æ›´æ–° (ä¾‹å¦‚åªæœ‰åƒ¹æ ¼ä½†ç¼ºæŒ‡æ¨™)ï¼ŒStep 7 ä¹Ÿèƒ½è£œç®—
            step7_calc_indicators(data)
            
            # [æ–°å¢] æ›´æ–°å¾Œæ¸…é™¤å¿«å–ï¼Œç¢ºä¿æƒæåŠŸèƒ½è®€åˆ°æœ€æ–°æ•¸æ“š
            GLOBAL_INDICATOR_CACHE["data"] = {}
            print_flush("âœ“ ç³»çµ±å¿«å–å·²æ¸…é™¤ï¼Œä¸‹æ¬¡æƒæå°‡é‡æ–°è¼‰å…¥æœ€æ–°æ•¸æ“š")
        elif ch == '9':
            step2_download_tpex_daily()
            step3_download_twse_daily()
            step7_calc_indicators()
            GLOBAL_INDICATOR_CACHE["data"] = {}
            print_flush("âœ“ ç³»çµ±å¿«å–å·²æ¸…é™¤")
        elif ch == '0': break

def step6_verify_and_backfill(data=None, resume=False):
    """é©—è­‰è³‡æ–™å®Œæ•´æ€§èˆ‡å›è£œ - æ”¯æ´æ–·é»çºŒæŠ“"""
    print_flush("\n[Step 6] é©—è­‰è³‡æ–™å®Œæ•´æ€§èˆ‡å›è£œ...")
    
    if data is None:
        data = step4_load_data()
    
    # æ”¶é›†éœ€è¦å›è£œçš„è‚¡ç¥¨
    tasks = []
    with db_manager.get_connection() as conn:
        cur = conn.cursor()
        for code, info in data.items():
            cur.execute("SELECT COUNT(*) FROM stock_data WHERE code=?", (code,))
            count = cur.fetchone()[0]
            if count < MIN_DATA_COUNT:
                # [å„ªåŒ–] åŠ å…¥æœ€æ–°æ—¥æœŸä»¥ä¾›æ¯”å°
                tasks.append((code, info['name'], count, info['date']))
    
    if not tasks:
        print_flush(f"âœ“ æ‰€æœ‰è‚¡ç¥¨è³‡æ–™å®Œæ•´ (çš† >= {MIN_DATA_COUNT} ç­†)")
        return set()

    # è®€å–é€²åº¦
    progress = load_progress()
    start_idx = progress.get("last_code_index", 0) if resume else 0
    
    # é‡ç½®é€²åº¦ï¼ˆå¦‚æœä¸æ˜¯ resumeï¼‰
    if not resume:
        save_progress(last_idx=0)
        start_idx = 0
    
    # [ä¿®æ­£] æª¢æŸ¥é€²åº¦ç´¢å¼•æ˜¯å¦æœ‰æ•ˆ
    if start_idx >= len(tasks):
        print_flush(f"âš  é€²åº¦ç´€éŒ„ ({start_idx}) è¶…å‡ºç•¶å‰ä»»å‹™ç¯„åœ ({len(tasks)})ï¼Œé‡ç½®é€²åº¦å¾é ­é–‹å§‹...")
        start_idx = 0
        save_progress(last_idx=0)
    
    print_flush(f"âš  ç™¼ç¾ {len(tasks)} æª”è‚¡ç¥¨è³‡æ–™ä¸è¶³ï¼Œé–‹å§‹å›è£œ...")
    if start_idx > 0:
        print_flush(f"ğŸ“ å¾ç¬¬ {start_idx+1} æª”ç¹¼çºŒï¼ˆå·²å®Œæˆ {start_idx} æª”ï¼‰")
    
    # ä½¿ç”¨DataSourceManageré€²è¡Œå›è£œ
    data_source_manager = DataSourceManager(silent=True)
    
    tracker = ProgressTracker(total_lines=3)
    
    success_count = 0
    fail_count = 0
    skip_count = start_idx
    
    updated_codes = set()
    
    with tracker:
        # å„ªåŒ–: ç§»å‡ºè¿´åœˆï¼Œé¿å…é‡è¤‡è«‹æ±‚
        latest_date = get_latest_market_date()
        end_date = latest_date
        start_date = (datetime.strptime(latest_date, "%Y-%m-%d") - timedelta(days=1095)).strftime("%Y-%m-%d")
        
        for i in range(start_idx, len(tasks)):
            code, name, count, last_date = tasks[i]
            
            # [çœéŒ¢å„ªåŒ–] å¦‚æœè³‡æ–™åº«æœ€æ–°æ—¥æœŸç­‰æ–¼å¸‚å ´æœ€æ–°æ—¥æœŸï¼Œä»£è¡¨ä»Šæ—¥å·²æ›´æ–°éï¼Œè·³é API
            if last_date == latest_date:
                tracker.update_lines(
                    f"æ­£åœ¨å›è£œ: {code} {name}",
                    f"ç›®å‰ç­†æ•¸: {count} -> ç›®æ¨™: {MIN_DATA_COUNT}",
                    f"ç‹€æ…‹: ä»Šæ—¥å·²æ›´æ–° (è·³é API è«‹æ±‚)"
                )
                success_count += 1
                updated_codes.add(code) # ä»åŠ å…¥æ›´æ–°åˆ—è¡¨ä»¥è§¸ç™¼è¨ˆç®—
                save_progress(last_idx=i)
                continue

            tracker.update_lines(
                f"æ­£åœ¨å›è£œ: {code} {name}",
                f"ç›®å‰ç­†æ•¸: {count} -> ç›®æ¨™: {MIN_DATA_COUNT}",
                f"é€²åº¦: {i+1}/{len(tasks)} | æˆåŠŸ: {success_count} | å¤±æ•—: {fail_count}"
            )
            
            # Debug info
            # print_flush(f"  -> Fetching {code} ({start_date} ~ {end_date})...")
            
            df = data_source_manager.fetch_history(code, start_date, end_date)
            
            if df is not None and not df.empty:
                try:
                    with db_manager.get_connection() as conn:
                        cur = conn.cursor()
                        inserted = 0
                        for _, row in df.iterrows():
                            cur.execute("""
                                INSERT OR IGNORE INTO stock_data 
                                (code, name, date, open, high, low, close, volume)
                                VALUES (?,?,?,?,?,?,?,?)
                            """, (code, name, row['date'], row.get('open'), row.get('high'), 
                                  row.get('low'), row.get('close'), row.get('volume')))
                            if cur.rowcount > 0:
                                inserted += 1
                        conn.commit()
                    if inserted > 0:
                        success_count += 1
                        updated_codes.add(code)
                        # print_flush(f"  -> Inserted {inserted} rows")
                    else:
                        # [ä¿®æ­£] å¦‚æœæœ‰æŠ“åˆ°è³‡æ–™ä½†æ²’æ–°å¢ï¼Œä»£è¡¨å·²æ˜¯æœ€æ–° (å¯èƒ½æ˜¯æ–°è‚¡)
                        # è¦–ç‚ºæˆåŠŸï¼Œä¸¦åŠ å…¥æ›´æ–°åˆ—è¡¨ä»¥è§¸ç™¼ Step 7 (å›æ‡‰ä½¿ç”¨è€…æœŸå¾…)
                        success_count += 1
                        updated_codes.add(code)
                        tracker.update_lines(
                            f"æ­£åœ¨å›è£œ: {code} {name}",
                            f"ç›®å‰ç­†æ•¸: {count} -> ç›®æ¨™: {MIN_DATA_COUNT}",
                            f"ç‹€æ…‹: è³‡æ–™å·²æ˜¯æœ€æ–° (å¯èƒ½æ˜¯æ–°ä¸Šå¸‚è‚¡)"
                        )
                        # fail_count += 1
                        # print_flush(f"  -> No new rows inserted (Data overlap)")
                except Exception as e:
                    fail_count += 1
                    logging.error(f"DB Write Error {code}: {e}")
            else:
                # çœŸçš„æŠ“ä¸åˆ°è³‡æ–™æ‰ç®—å¤±æ•—
                fail_count += 1
                # print_flush(f"  -> Fetch failed or empty")
            
            # æ¯å®Œæˆä¸€æª”å°±ä¿å­˜é€²åº¦
            save_progress(last_idx=i)
    
    print_flush(f"âœ“ å›è£œå®Œæˆ - æˆåŠŸ: {success_count} å¤±æ•—: {fail_count} è·³é: {skip_count}")
    return updated_codes

def step7_calc_indicators(data=None, force=False):
    """[Step 7] è¨ˆç®—æ‰€æœ‰è‚¡ç¥¨çš„æŠ€è¡“æŒ‡æ¨™ä¸¦å¯«å…¥è³‡æ–™åº« (ä¿®æ­£åƒæ•¸é †åºç‰ˆ)"""
    print_flush("\n[Step 7] è¨ˆç®—æŠ€è¡“æŒ‡æ¨™...")
    
    if data is None:
        data = step4_load_data()
    
    if not data:
        print_flush("âŒ ç„¡è‚¡ç¥¨è³‡æ–™å¯è¨ˆç®—")
        return {}
    
    # æº–å‚™è¦è™•ç†çš„è‚¡ç¥¨åˆ—è¡¨
    stocks = [(code, info['name']) for code, info in data.items()]
    total = len(stocks)
    
    if total == 0:
        print_flush("âŒ ç„¡è‚¡ç¥¨éœ€è¦è¨ˆç®—æŒ‡æ¨™")
        return {}
    
    print_flush(f"ğŸ“Š æº–å‚™è¨ˆç®— {total} æª”è‚¡ç¥¨çš„æŠ€è¡“æŒ‡æ¨™...")
    
    tracker = ProgressTracker(total_lines=3)
    pending_updates = []
    batch_size = 50
    
    with tracker:
        for i, (code, name) in enumerate(stocks):
            status_msg = "è™•ç†ä¸­..."
            
            try:
                # è¨ˆç®—è©²è‚¡ç¥¨æ‰€æœ‰æŒ‡æ¨™ (è™•ç†å…¨éƒ¨æ­·å²è³‡æ–™)
                indicators_list = calculate_stock_history_indicators(code, display_days=None)
                
                if indicators_list:
                    for ind in indicators_list:
                        # [é‡è¦ä¿®æ­£] åƒæ•¸é †åºå¿…é ˆåš´æ ¼å°æ‡‰ä¸‹æ–¹çš„ SQL èªå¥
                        # SQL çµæ§‹: SET col1=?, col2=?, ... WHERE code=? AND date=?
                        # å› æ­¤ tuple é †åºå¿…é ˆæ˜¯: (col1_val, col2_val, ..., code_val, date_val)
                        pending_updates.append((
                            ind.get('MA3'), ind.get('MA20'), ind.get('MA60'), ind.get('MA120'), ind.get('MA200'),
                            ind.get('WMA3'), ind.get('WMA20'), ind.get('WMA60'), ind.get('WMA120'), ind.get('WMA200'),
                            ind.get('MFI'), ind.get('VWAP'), ind.get('CHG14'), ind.get('RSI'), ind.get('MACD'), ind.get('SIGNAL'),
                            ind.get('POC'), ind.get('VP_upper'), ind.get('VP_lower'),
                            ind.get('Month_K'), ind.get('Month_D'),
                            ind.get('Daily_K'), ind.get('Daily_D'),
                            ind.get('Week_K'), ind.get('Week_D'),
                            ind.get('MA3_prev'), ind.get('MA20_prev'), ind.get('MA60_prev'), ind.get('MA120_prev'), ind.get('MA200_prev'),
                            ind.get('WMA3_prev'), ind.get('WMA20_prev'), ind.get('WMA60_prev'), ind.get('WMA120_prev'), ind.get('WMA200_prev'),
                            ind.get('MFI_prev'), ind.get('VWAP_prev'), ind.get('CHG14_prev'),
                            ind.get('Month_K_prev'), ind.get('Month_D_prev'),
                            ind.get('Daily_K_prev'), ind.get('Daily_D_prev'),
                            ind.get('Week_K_prev'), ind.get('Week_D_prev'),
                            ind.get('close_prev'), ind.get('vol_prev'),
                            # [ä¿®æ­£è™•] æ–°å¢æ¬„ä½å¿…é ˆæ”¾åœ¨ WHERE åƒæ•¸ä¹‹å‰
                            ind.get('Smart_Score'), ind.get('SMI_Signal'), ind.get('NVI_Signal'), ind.get('VSA_Signal'), ind.get('SVI_Signal'),
                            # [ä¿®æ­£è™•] code å’Œ date å¿…é ˆæ”¾åœ¨æœ€å¾Œé¢ï¼Œå°æ‡‰ WHERE code=? AND date=?
                            code, ind.get('date')
                        ))
                    
                    status_msg = "è¨ˆç®—å®Œæˆ" if indicators_list else "ç„¡æ•¸æ“š/å¤±æ•—"
                    
            except Exception as e:
                status_msg = f"éŒ¯èª¤: {e}"
            
            # æ›´æ–°é€²åº¦é¡¯ç¤º
            tracker.update_lines(
                f'æ­£åœ¨è¨ˆç®—: {code} {name}',
                f'é€²åº¦: {i+1}/{total} (Buffer: {len(pending_updates)})',
                f'ç‹€æ…‹: {status_msg}'
            )
            
            # æ‰¹é‡å¯«å…¥è³‡æ–™åº« (ä¸»åŸ·è¡Œç·’åŸ·è¡Œï¼Œé¿å…é–æ­»)
            if len(pending_updates) >= batch_size or (i == total - 1 and pending_updates):
                try:
                    with db_manager.get_connection() as conn:
                        cur = conn.cursor()
                        cur.executemany("""
                            UPDATE stock_data SET
                                ma3=?, ma20=?, ma60=?, ma120=?, ma200=?,
                                wma3=?, wma20=?, wma60=?, wma120=?, wma200=?,
                                mfi14=?, vwap20=?, chg14_pct=?, rsi=?, macd=?, signal=?,
                                vp_poc=?, vp_upper=?, vp_lower=?,
                                month_k=?, month_d=?,
                                daily_k=?, daily_d=?,
                                week_k=?, week_d=?,
                                ma3_prev=?, ma20_prev=?, ma60_prev=?, ma120_prev=?, ma200_prev=?,
                                wma3_prev=?, wma20_prev=?, wma60_prev=?, wma120_prev=?, wma200_prev=?,
                                mfi14_prev=?, vwap20_prev=?, chg14_pct_prev=?,
                                month_k_prev=?, month_d_prev=?,
                                daily_k_prev=?, daily_d_prev=?,
                                week_k_prev=?, week_d_prev=?,
                                close_prev=?, vol_prev=?,
                                smart_score=?, smi_signal=?, nvi_signal=?, vsa_signal=?, svi_signal=?
                            WHERE code=? AND date=?
                        """, pending_updates)
                        conn.commit()
                except Exception as e:
                    tracker.update_lines(
                        f'æ­£åœ¨è¨ˆç®—: {code} {name}',
                        f'é€²åº¦: {i+1}/{total} (Buffer: {len(pending_updates)})',
                        f'ç‹€æ…‹: å¯«å…¥å¤±æ•—! {e}'
                    )
                    print_flush(f"\nâŒ æ‰¹é‡å¯«å…¥éŒ¯èª¤: {e}")
                finally:
                    pending_updates.clear()
    
    print_flush(f"âœ“ å·²å®Œæˆ {total} æª”è‚¡ç¥¨çš„æŒ‡æ¨™è¨ˆç®—èˆ‡å¯«å…¥")
    return step4_load_data()

def backup_menu():
    """è³‡æ–™åº«å‚™ä»½èˆ‡é‚„åŸé¸å–®"""
    while True:
        print_flush("\n" + "="*60)
        print_flush("ã€è³‡æ–™åº«å‚™ä»½èˆ‡é‚„åŸã€‘")
        print_flush("="*60)
        print_flush("[1] å‚™ä»½è³‡æ–™åº«")
        print_flush("[2] é‚„åŸè³‡æ–™åº«")
        print_flush("[3] åˆ—å‡ºç¾æœ‰å‚™ä»½")
        print_flush("[0] è¿”å›")
        
        choice = read_single_key("è«‹é¸æ“‡: ")
        
        if choice == '1':
            # å‚™ä»½è³‡æ–™åº«
            try:
                import shutil
                timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                backup_file = BACKUP_DIR / f"taiwan_stock_backup_{timestamp}.db"
                shutil.copy2(DB_FILE, backup_file)
                print_flush(f"âœ“ å‚™ä»½æˆåŠŸ: {backup_file}")
            except Exception as e:
                print_flush(f"âŒ å‚™ä»½å¤±æ•—: {e}")
        
        elif choice == '2':
            # é‚„åŸè³‡æ–™åº«
            backups = sorted(BACKUP_DIR.glob("*.db"), reverse=True)
            if not backups:
                print_flush("âŒ æ²’æœ‰å¯ç”¨çš„å‚™ä»½æª”æ¡ˆ")
                continue
            
            print_flush("\nå¯ç”¨å‚™ä»½:")
            for i, b in enumerate(backups[:10], 1):
                print_flush(f"  [{i}] {b.name}")
            
            try:
                idx = int(input("è«‹é¸æ“‡è¦é‚„åŸçš„å‚™ä»½ (è¼¸å…¥æ•¸å­—): ").strip()) - 1
                if 0 <= idx < len(backups):
                    import shutil
                    shutil.copy2(backups[idx], DB_FILE)
                    print_flush(f"âœ“ é‚„åŸæˆåŠŸ: {backups[idx].name}")
                else:
                    print_flush("âŒ ç„¡æ•ˆçš„é¸æ“‡")
            except Exception as e:
                print_flush(f"âŒ é‚„åŸå¤±æ•—: {e}")
        
        elif choice == '3':
            # åˆ—å‡ºå‚™ä»½
            backups = sorted(BACKUP_DIR.glob("*.db"), reverse=True)
            if not backups:
                print_flush("âŒ æ²’æœ‰å‚™ä»½æª”æ¡ˆ")
            else:
                print_flush(f"\næ‰¾åˆ° {len(backups)} å€‹å‚™ä»½:")
                for b in backups[:20]:
                    size_mb = b.stat().st_size / (1024*1024)
                    print_flush(f"  â€¢ {b.name} ({size_mb:.2f} MB)")
        
        elif choice == '0':
            break

def delete_data_by_date():
    """åˆªé™¤æŒ‡å®šæ—¥æœŸçš„è³‡æ–™"""
    print_flush("\nã€åˆªé™¤æŒ‡å®šæ—¥æœŸè³‡æ–™ã€‘")
    print_flush("-" * 40)
    
    try:
        date_str = input("è«‹è¼¸å…¥è¦åˆªé™¤çš„æ—¥æœŸ (æ ¼å¼: YYYY-MM-DD): ").strip()
        
        # é©—è­‰æ—¥æœŸæ ¼å¼
        try:
            datetime.strptime(date_str, "%Y-%m-%d")
        except ValueError:
            print_flush("âŒ æ—¥æœŸæ ¼å¼éŒ¯èª¤ï¼Œè«‹ä½¿ç”¨ YYYY-MM-DD æ ¼å¼")
            return
        
        # å…ˆæŸ¥è©¢æœ‰å¤šå°‘ç­†
        with db_manager.get_connection() as conn:
            cur = conn.cursor()
            cur.execute("SELECT COUNT(*) FROM stock_data WHERE date=?", (date_str,))
            count = cur.fetchone()[0]
        
        if count == 0:
            print_flush(f"âš  æ—¥æœŸ {date_str} æ²’æœ‰ä»»ä½•è³‡æ–™")
            return
        
        print_flush(f"âš  å°‡åˆªé™¤ {date_str} çš„ {count} ç­†è³‡æ–™")
        confirm = input("ç¢ºå®šè¦åˆªé™¤å—? (y/n): ").strip().lower()
        
        if confirm == 'y':
            with db_manager.get_connection() as conn:
                cur = conn.cursor()
                cur.execute("DELETE FROM stock_data WHERE date=?", (date_str,))
                conn.commit()
            print_flush(f"âœ“ å·²åˆªé™¤ {count} ç­†è³‡æ–™")
        else:
            print_flush("å·²å–æ¶ˆ")
    
    except Exception as e:
        print_flush(f"âŒ åˆªé™¤å¤±æ•—: {e}")

def maintenance_menu():
    """ç³»çµ±ç¶­è­·é¸å–®"""
    while True:
        print_flush("\n" + "="*60)
        print_flush("ã€ç³»çµ±ç¶­è­·ã€‘")
        print_flush("="*60)
        print_flush("[1] è³‡æ–™åº«å‚™ä»½èˆ‡é‚„åŸ")
        print_flush("[2] åˆªé™¤æŒ‡å®šæ—¥æœŸè³‡æ–™")
        print_flush("[3] æª¢æŸ¥ API é€£ç·šç‹€æ…‹")
        print_flush("[4] æª¢æŸ¥è³‡æ–™åº«ç©ºå€¼ç‡")
        print_flush("[5] å¼·åˆ¶é‡ç®—æ‰€æœ‰æŒ‡æ¨™ (ä¿®å¾©æ•¸æ“šç”¨)")
        print_flush("[0] è¿”å›ä¸»é¸å–®")
        
        choice = read_single_key("è«‹é¸æ“‡: ")
        
        if choice == '1': backup_menu()
        elif choice == '2': delete_data_by_date()
        elif choice == '3': check_api_status()
        elif choice == '4': check_db_nulls()
        elif choice == '5':
            print_flush("\nâš  è­¦å‘Š: æ­¤æ“ä½œå°‡é‡æ–°è¨ˆç®—æ‰€æœ‰è‚¡ç¥¨çš„æŒ‡æ¨™ï¼Œå¯èƒ½éœ€è¦è¼ƒé•·æ™‚é–“ (ç´„ 10-20 åˆ†é˜)ã€‚")
            confirm = input("ç¢ºå®šè¦åŸ·è¡Œå—? (y/n) [é è¨­y]: ").strip().lower()
            if not confirm or confirm == 'y':
                step7_calc_indicators(force=True)
            else:
                print_flush("å·²å–æ¶ˆ")
        elif choice == '0': break

def integrated_quick_integrity_check():
    print_flush("\n[å¿«é€Ÿæª¢æŸ¥] åŸ·è¡Œä¸­...")
    step4_check_data_gaps()

def integrated_full_integrity_check(days=250):
    print_flush(f"\n[å…¨é¢æª¢æŸ¥] æª¢æŸ¥æœ€è¿‘ {days} å¤©æ•¸æ“š...")
    step4_check_data_gaps()

def integrated_architecture_diagnosis():
    print_flush("\n[æ¶æ§‹è¨ºæ–·] æª¢æŸ¥è³‡æ–™åº«çµæ§‹...")
    try:
        ensure_db()
        print_flush("âœ“ è³‡æ–™åº«çµæ§‹æ­£å¸¸")
    except Exception as e:
        print_flush(f"âŒ æ¶æ§‹ç•°å¸¸: {e}")

def integrated_fix_missing_dates():
    print_flush("\n[ä¿®å¾©] åŠŸèƒ½å°šæœªå¯¦ä½œ")

def check_db_nulls():
    """æª¢æŸ¥è³‡æ–™åº«ç©ºå€¼ç‡"""
    print_flush("\n[æª¢æŸ¥] è³‡æ–™åº«ç©ºå€¼ç‡åˆ†æ...")
    try:
        with db_manager.get_connection() as conn:
            cursor = conn.cursor()
            
            # Get all columns
            cursor.execute("PRAGMA table_info(stock_data)")
            columns = [row[1] for row in cursor.fetchall()]
            
            # Get latest date
            cursor.execute("SELECT MAX(date) FROM stock_data")
            latest_date = cursor.fetchone()[0]
            
            # Count total rows and latest rows
            cursor.execute("SELECT COUNT(*) FROM stock_data")
            total_rows = cursor.fetchone()[0]
            
            cursor.execute("SELECT COUNT(*) FROM stock_data WHERE date=?", (latest_date,))
            latest_rows = cursor.fetchone()[0]
            
            if total_rows == 0:
                print_flush("âŒ è³‡æ–™åº«ç„¡æ•¸æ“š")
                return

            print_flush(f"åˆ†æç¯„åœ: å…¨æ­·å² ({total_rows} ç­†) vs æœ€æ–°æ—¥æœŸ {latest_date} ({latest_rows} ç­†)")
            print_flush("-" * 75)
            print_flush(f"{'æ¬„ä½åç¨±':<20} | {'å…¨æ­·å²ç©ºå€¼%':<12} | {'æœ€æ–°æ—¥ç©ºå€¼%':<12} | {'ç‹€æ…‹':<10}")
            print_flush("-" * 75)
            
            # Check nulls for each column
            for col in columns:
                # éš±è—å»¢æ£„æ¬„ä½
                if col in ['kd_k', 'kd_d', 'kd_golden_cross']:
                    continue
                    
                # å…¨æ­·å²ç©ºå€¼
                cursor.execute(f"SELECT COUNT(*) FROM stock_data WHERE {col} IS NULL")
                null_count = cursor.fetchone()[0]
                null_pct = (null_count / total_rows) * 100
                
                # æœ€æ–°æ—¥ç©ºå€¼
                cursor.execute(f"SELECT COUNT(*) FROM stock_data WHERE date=? AND {col} IS NULL", (latest_date,))
                latest_null_count = cursor.fetchone()[0]
                latest_null_pct = (latest_null_count / latest_rows) * 100
                
                # ç‹€æ…‹åˆ¤æ–·
                status = "OK"
                if latest_null_pct > 10:
                    status = "ç¼ºè³‡æ–™ (!)"
                elif latest_null_pct > 0:
                    status = "éƒ¨åˆ†ç¼º"
                
                # æ ¼å¼åŒ–è¼¸å‡º
                print_flush(f"{col:<20} | {null_pct:<10.2f}% | {latest_null_pct:<10.2f}% | {status}")
                
            print_flush("-" * 75)
            print_flush("èªªæ˜:")
            print_flush("1. [å…¨æ­·å²ç©ºå€¼%] é«˜ (å¦‚ MA200 ç´„ 40%) æ˜¯æ­£å¸¸çš„ï¼Œä»£è¡¨æ—©æœŸè³‡æ–™ä¸è¶³ç„¡æ³•è¨ˆç®—ã€‚")
            print_flush("2. [æœ€æ–°æ—¥ç©ºå€¼%] æ‡‰æ¥è¿‘ 0%ã€‚è‹¥ MA200 åœ¨æœ€æ–°æ—¥ä»æœ‰ç©ºå€¼ï¼Œä»£è¡¨è©²è‚¡ä¸Šå¸‚æœªæ»¿ 200 å¤©ã€‚")
            
            print_flush("\n" + "="*50)
            print_flush("æ˜¯å¦ç«‹å³åŸ·è¡Œ [1]~[7] å®Œæ•´æ›´æ–°ä»¥ä¿®å¾©ç¼ºå¤±æ•¸æ“šï¼Ÿ")
            # [ä¿®æ­£] æ›´æ¸…æ¥šçš„æç¤ºæ–‡å­—
            ans = input("è¼¸å…¥ y åŸ·è¡Œä¿®å¾©ï¼Œè¼¸å…¥ n è¿”å›é¸å–®: ").strip().lower()
            
            if not ans or ans == 'y':
                # å‘¼å«ä¸€éµæ›´æ–°é‚è¼¯ (Option 8 çš„é‚è¼¯)
                step1_fetch_stock_list()
                updated_codes = set()
                s2 = step2_download_tpex_daily()
                if isinstance(s2, set): updated_codes.update(s2)
                s3 = step3_download_twse_daily()
                if isinstance(s3, set): updated_codes.update(s3)
                step5_clean_delisted()
                step4_check_data_gaps()
                data = step4_load_data()
                step6_verify_and_backfill(data, resume=True)
                step7_calc_indicators(data)
                GLOBAL_INDICATOR_CACHE["data"] = {}
                print_flush("âœ“ ç³»çµ±å¿«å–å·²æ¸…é™¤ï¼Œæ›´æ–°å®Œæˆ")
            
    except Exception as e:
        print_flush(f"âŒ æª¢æŸ¥å¤±æ•—: {e}")


def diagnostic_menu():
    """è¨ºæ–·èˆ‡ä¿®å¾©é¸å–®"""
    while True:
        print_flush("\n" + "="*60)
        print_flush("ğŸ”§ è¨ºæ–·èˆ‡ä¿®å¾©")
        print_flush("="*60)
        print_flush("[1] å¿«é€Ÿå®Œæ•´æ€§æª¢æŸ¥ (æœ€è¿‘30å¤©)")
        print_flush("[2] å…¨é¢å®Œæ•´æ€§æª¢æŸ¥èˆ‡ä¿®å¾© (æœ€è¿‘{MIN_DATA_COUNT}å¤©)")
        print_flush("[3] æ¶æ§‹è¨ºæ–·èˆ‡ç•°å¸¸æª¢æ¸¬")
        print_flush("[4] ä¿®å¾©æŒ‡å®šè‚¡ç¥¨ç¼ºå¤±æ—¥æœŸ")
        print_flush("[0] è¿”å›ä¸»é¸å–®")
        
        choice = read_single_key("è«‹é¸æ“‡: ")
        
        if choice == '1':
            integrated_quick_integrity_check()
        elif choice == '2':
            integrated_full_integrity_check(days=MIN_DATA_COUNT)
        elif choice == '3':
            integrated_architecture_diagnosis()
        elif choice == '4':
            integrated_fix_missing_dates()
        elif choice == '0':
            break

def main_menu():
    # åˆå§‹åŒ–è³‡æ–™åº«
    try:
        ensure_db()
    except Exception as e: print(f"DB Init Error: {e}")

    first_run = True
    while True:
        if first_run:
            display_system_status() # æ¢å¾©é¡¯ç¤ºï¼Œä½†å·²å„ªåŒ–ä¸æª¢æŸ¥ API
            first_run = False

        print_flush("\n" + "="*80)
        print_flush("å°ç£è‚¡ç¥¨åˆ†æç³»çµ± v40 Enhanced (å‡ç·šå¤šé ­å„ªåŒ–ç‰ˆ)")
        print_flush("="*80)
        print_flush("[1] è³‡æ–™ç®¡ç† (æ›´æ–°/è£œæ¼/è¨ˆç®—)")
        print_flush("[2] å¸‚å ´æƒæ (ç­–ç•¥/ç¯©é¸)")
        print_flush("[3] ç³»çµ±ç¶­è­·èˆ‡è¨ºæ–· (å‚™ä»½/æª¢æŸ¥)")
        print_flush("[0] é›¢é–‹")
        print_flush("-" * 80)
        print_flush("æç¤º: ç›´æ¥è¼¸å…¥è‚¡è™Ÿ (å¦‚ 2330) å¯æŸ¥è©¢å€‹è‚¡")
        
        # æ¨™æº–è¼¸å…¥é‚è¼¯ (éœ€æŒ‰ Enter)
        try:
            choice = input("è«‹é¸æ“‡: ").strip()
        except EOFError:
            break
        
        if choice == '1': data_management_menu()
        elif choice == '2': market_scan_menu()
        elif choice == '3': maintenance_menu()
        elif choice == '0': sys.exit(0)
        elif len(choice) == 4 and choice.isdigit():
            name = get_correct_stock_name(choice)
            
            # è©¢å•é¡¯ç¤ºå¤©æ•¸ - è·¨å¹³å°ç‰ˆæœ¬
            try:
                days_input = input("é¡¯ç¤ºå¤©æ•¸(é è¨­30å¤©): ").strip()
                days = int(days_input) if days_input.isdigit() else 30
            except:
                days = 30
            
            res = calculate_stock_history_indicators(choice, display_days=days)
            if res:
                print_flush(f"\nã€{choice} {name}ã€‘è¿‘æœŸèµ°å‹¢:")
                print_flush(format_scan_result_list(choice, name, res))
            else:
                print_flush("âŒ æŸ¥ç„¡è³‡æ–™")
                time.sleep(1)
        elif len(choice) > 1:
             print_flush("âŒ è¼¸å…¥ç„¡æ•ˆ")
             time.sleep(0.5)

def load_indicators_cache():
    """è¼‰å…¥æŒ‡æ¨™å¿«å– (åªè®€å– DBï¼Œä¸å¼·åˆ¶é‡ç®—)"""
    print_flush("æ­£åœ¨è¼‰å…¥æŒ‡æ¨™æ•¸æ“š...")
    data = step4_load_data()
    if not data:
        return {}
    return data

if __name__ == "__main__":
    main_menu()